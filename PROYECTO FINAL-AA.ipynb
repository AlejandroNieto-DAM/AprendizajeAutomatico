{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XqnXgEmJ7NerSaiUsokVUrXdm2Pw4hWB","timestamp":1686051976288}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **PROYECTO FINAL-AA**\n","# Valor: 25 points | Fecha de entrega límite: 19 Junio | Subir a PRADO: https://pradogrado2223.ugr.es/"],"metadata":{"id":"ZPIqgzEtOtfi"}},{"cell_type":"markdown","source":["El Proyecto final tiene como objetivo mostrar el conocimiento global adquirido a lo largo del curso. Dicho conocimiento se valorará a partir de la metodología usada y la justificación de todos los aspectos de la misma. La ausencia de una justificación adecuada en las decisiones y métodos usados impide su valoración en la nota.\n","\n","Este proyecto se focaliza en el ajuste y selección del mejor predictor para una BBDD (UCI o Kaggle) con el apoyo de la libreria Scikit-Learn (ver fichero de BBDDs ofertadas en PRADO). Esta librería contiene funciones de muy alto nivel que pueden ser muy útiles si se comprende bien su funcionamiento. Por tanto, las funciones que se usen de Scikit-Learn  deben de justificarse y explicar con que objetivo se usan y el significado de todos sus parámetros y funciionaluidades.  Los valores fijados por defecto en la librería no se consideran elecciones justificadas a priori. Decisiones sin justificación y resultados sin interpretación  no serán considerados válidos ni puntuados.\n","\n","Especial atención se deberá de poner en la calidad de la metodología. El uso de las herramientas de scikit-learn para optimizar por VC en una misma llamada todos los parámetros e hiperparámetros de un modelo no está permitido. Se ha de optimizar cada parte  de forma individual justificando cada uno de los pasos dados.\n","\n","**Modelos a considerar:** *Si alguno de los modelos mencionados a continuación no hubiese sido explicado en clase quedará fuera de las opciones.*\n","\n","**Mejor Modelo Lineal**  **(Obligatorio)**\n","\n","**Perceptron Multicapa**. Considerar una arquitecturas de 3  capas  y un número de unidades por capa en el rango 50-100. Considerar el número de neuronas por capa como un hiperparámetro.\n","\n","**Máquina de Soporte de Vectores (SVM)**: se recomienda el núcleo RBF-Gaussiano o el polinomial. Encontrar el mejor valor para los parámetros libres hasta una precisión de 2 cifras (enteras o decimales) (hacer una búsqueda dicotómica)\n","\n","**Boosting**: Se recomienda que para clasificación se usen funciones ``stump''. Para regresión se recomiendan los árboles como regresores simples, justificando el valor del parámetro de aprendizaje.\n","\n","**Random Forest**: Usar como hiperparámetros los valores que por defecto se dan en teoría y experimentar para obtener el número de árboles adecuado.\n","\n","**Red de Funciones de base Radial**:  Fijar el valor del número de núcleos a usar, K,  y usar el algoritmo de k-medias para estimar sus localizaciones. Evaluar  distintos valores de K como criterio para la elección del K final.\n","\n","**OBJETIVO**: Buscar el mejor modelo posible para la base de datos seleccionada y justificar cada uno de los  pasos dados para conseguirlo. En regresión, se recomienda usar penalización LASSO para el proceso de selección de variables. El uso de las técnicas de reducción de dimensionalidad, ej. PCA o Random Projection debe de justificarse con argumentos correctos. Todos los proyectos deben justificar los siguientes apartados:\n","\n"],"metadata":{"id":"25ItnYlETimt"}},{"cell_type":"markdown","source":["# **Guía de realización:**\n","\n","1.-Todos los proyectos son para **dos alumnos**. Se podrá autorizar a un solo estudiante si el número total de estudiantes es impar o el caso es extraordinario.\\\n","\n","2.- Se oferta una conjunto amplio de BBDD, entre las cuales debe elegirse varias en orden de interés. Se asignará por el profesor una de ellas intentando el menor solapamiento posible entre todos los proyectos. Habrá una semana para hacer la propuesta de participantes y BBDDA elegidas.\n","\n","2.-Una vez elegido el proyecto, se subirá a PRADO el nombre de los alumnos participantes y la propuesta de proyecto. **SOLO UNA VEZ (1 alumno)**. La aprobación por parte del profesor aparecerá en PRADO.\n","\n","3.-El **1 de Junio** todos los alumnos de proyecto deberán tenerlo asignado. Cambios posteriores de proyecto/BBDD solo serán aprobados si aparecen condiciones imprevistas que impiden la realización del previamenbte asignado.\n","\n","4.- Ambos alumnos reciben la misma nota\\\n","\n","5.- Scikit-Leran es la librería soporte a usar. Si se usan módulos de alto nivel de dicha librería deben de justificarse cada uno de sus argumentos. En caso contrario, sólo se valora su uso. El uso intensivo de módulos de alto nivel podría disminuir, muy notablemente, la contribución personal y la nota.\n","\n","6.-Todos los proyectos deben entregar el  cuaderno Colab mopdelo relleno con los resultados obtenidos.\n","\n","# **Puntuaciones:**\n","Es obligatorio comparar hipótesis de al menos DOS modelos no-lineales y  un modelo lineal para poder optar a la puntuación máxima de 25 puntos. Las opciones son:\n","\n","1. Hasta 15 puntos. Aquellos proyectos que solo comparen  hipótesis de un modelo no-lineal frente a un modelo lineal.\n","2. Hasta 20 puntos. Aquellos proyectos que seleccionen entre tres modelos (funciones+algoritmos. Uno lineal.\n","3. Hasta 25 puntos. Aquellos proyectos que comparen hipótesis de al menos dos modelos no-lineales y un modelo lineal.\n","\n","BONUS.  A quienes habiendo alcanzado más de 22 puntos en la parte obligatoria, 3 puntos adicionales por cada técnica adicional incluida en la comparación y correctamente ajustada.\n","\n","\n","# **FORMATO DE ENTREGA**:\n","\n","1. El cuaderno debe incluir al comienzo del mismo un **enlace** para descargar el conjunto de **datos FINAL utilizado en entrenamiento y test**. **NO SUBIR LOS DATOS A PRADO*\n","2.-**El cuaderno debe ejecutarse sin errores de principio a fin**. No se valorarán aquellos proyectos con errores de ejecución.\n","3.-Subir a PRADO solo el cuaderno .ipynb y posibles ficheros auxiliares (.py).\n"],"metadata":{"id":"N-lGLNYUp5YK"}},{"cell_type":"markdown","source":["\n","Puntos que se espera encontrar en el prouyecto:\n","\n","1.   Definición del problema a resolver y enfoque elegido para ello.\n","2.   Codificación y decuaciíon de los datos de entrada para hacerlos útiles a los algoritmos.\n","3. Valoración (en su caso) de la necesidad/interés de seleccionar un subconjunto de variables para el ajuste.\n","4. Necesidad de la normalización de los datos e interés de la técnica usada (en su caso)\n","5. Interés y justificación de la función/es de pérdida usada en el ajuste.\n","6. Argumentos a favor de la idoneidad de los modelos seleccionados para la BBDD.\n","7. Argumentar sobre la idoneidad de la regularización usada (en su caso) O por qué se ha elegido el modelo usad0\n","8. Algoritmo de aprendizaje usado en cada modelo, especificando y justificando los valores de todos los parámetros e hiperparámetros usados.\n","9. Selección de la mejor hipótesis. Justifique la técnica usada y calcule el error $E_{out}$ de dicha hipótesis.\n","10. Valoración de los resultados ( gráficas, métricas de error, análisis de residuos, etc )\n","11. Argumente que se ha obtenido la mejor de las posibles soluciones para la muestra dada. Argumentar en términos de los errores de ajuste y generalización.\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"SSD0EsJhtDfa"}},{"cell_type":"markdown","source":["**CRITERIOS PARA DATOS PERDIDOS:**\n","\n","No todos los algoritmos de aprendizaje necesitan sustituir los datos perdidos. En caso de necesitarse aplicar los siguientes:\n","\n","1. Cuando un item  de la muestra de datos tengan más del 10\\% de sus elemebntos perdidos puede eliminarse del conjunto de datos si no afecta al tamaño del conjunto de datos. Si es más del 20\\% debe eliminarse.\n","2. Para loos datos perdidos de variables con valores reales se aplicará el siguiente criterio: reemplazar por la suma del valor medio de dicha variable más un valor aleatorio en el intervalo $[-1.5\\sigma, 1.5\\sigma]$ siendo $\\sigma$ la desviación típica de la dicha variable.\n","3. Para los datos perdidos que sean de variables categóricas aplicar lo siguiente:\n","    1. Calcular  la distribución de probabilidad de las categorías en la columna, se obtiene una multinomial sobre las categorias.\n","    4. Calcular la distribución acumulada, sumando iterativamente la probabilidad de cada categoría. Tendreis un vector que toma valores crecientes de 0 a 1, y que además define intervalos de valores asignados a cada categoria.\n","    5. Sortear un número aleatorio uniforme en [0,1]\n","    6. Asignar la categoria que corresponda a ese valor dentro de [0,1].\n","\n","Usar el criterio de intervalos semi-abiertos por abajo, es decir, el extremo inferior de cada intervalo es un valor de dicho intervalo y el extremo superior del siguiente intervalo.\n","\n"],"metadata":{"id":"GIdf65qRx1cc"}},{"cell_type":"markdown","source":["**CRITERIOS PARA CLASES DESBALANCEADAS:**\n","\n","1. Si el tamaño de la clase más pequeña es suficiente para aprender con el modelo. Puede aplicar  ponderación de clases en la función de error. Otras técnicas disponibles en Scikit-Learn pueden usarse si se **justifica** su mayor idoneidad para el problema.\n","2. También puede usarse un enfoque de partición del conjunto  datos de entrenamiento en múltiples conjuntos homógeneos para su uso con un clasificador basado en un ``ensemble'' de clasificadores.\n","3. Si el tamaño de la clase no pemite aprender, entonces se puede eliminar la clase. En este caso se debe pedir la aprobación del profesor.\n","\n","El uso de resultados y enfoques existentes en la literatura sobre las bases de datos está permitido y de hecho se alienta, siempre y cuando se deja manifiestamente claro que uso se hace de dicha información/resultado y cual es la aportación del proyecto sobre la misma. En caso contrario se entenderá plagio. Incluir las referencias de la bibliografía usada.\n"],"metadata":{"id":"H2LPTRAfRtZo"}},{"cell_type":"markdown","source":["# **NOMBRE DE LOS ALUMNOS:**\n","\n","1. Rubén Morillas López\n","2. Alejandro Nieto Alarcón\n","\n","# **BASE DE DATOS SELECCIONADA**\n","1. Breast Cancer Wisconsin (Diagnostic)\n","\n","# **MODELO DE PROYECTO AL QUE OPTAN (15/20/25 puntos):**\n","2 modelos no lineales y 1 lineal"],"metadata":{"id":"btjruC-C0HnN"}},{"cell_type":"markdown","source":["# **COMIENZO DEL PROYECTO**"],"metadata":{"id":"0I-pM_F_1i29"}},{"cell_type":"markdown","source":["# Enlace a datos usados\n","https://consigna.ugr.es/?s=download&token=b0d2020e-3369-43ea-bf8e-64256532735c"],"metadata":{"id":"h2xmyBpNB1Pr"}},{"cell_type":"markdown","source":["# DEFINICION DEL PROBLEMA A RESOLVER Y ENFOQUE ELEGIDO PARA ELLO"],"metadata":{"id":"d13AFNVs5MZd"}},{"cell_type":"markdown","source":["El problema sobre el que vamos a tratar la práctica es el **Breast Cancer Wisconsin** este problema esta compuesto por una serie de variables categóricas [2:10] y la variable objetivo [11]. La primera variable no la hemos tenido en cuenta ya que simplemente es un identificador de la muestra que venía con los datos. Es un valor no predictivo por lo que no aporta información para nuestro objetivo que es el de predecir el cáncer de pecho. Las variables por las que está compuesto y que trataremos serán las siguientes (Todas ellas son categóricas con rango 1-10):\n","\n","**Clump Thickness**: Mide el grosor del tumor ya que las celulas benignas tienden a agruparse en monocapas mientras que las cancerígenas tienden a agruparse en multicapa.\n","\n","**Cell Size Uniformity**: Esta variable capta la uniformidad del tamaño ya que las células cancerígenas tienden a cambiar en tamaño y forma.\n","\n","**Cell shape uniformity**: Esta variable capta la uniformidad de la forma ya que las células cancerígenas tienden a cambiar en tamaño y forma.\n","\n","**Marginal adhesion**: Mide la adhesión marginal de las ceculas ya que las células normales tienden a permanecer juntas, mientras que las células cancerígenas tienden a perder esta capacidad, por lo que la pérdida de adhesión es un mal signo.\n","\n","**Single epithelial cell size**: Mide el tamaño de la célula epitelial unica. Esta relacionado con la uniformidad mencionada anteriormente. Las celulas epiteliales que están significativamente agrandas es un síntoma de una celula maligna.\n","\n","**Bare nuclei**:  Mide como un nucleo de una célula no esta rodeado por citoplasma. Esto se ve normalmente en tumores benignos.\n","\n","**Bland_chromatin**: Almacena información sobre como de uniforme es la textura del nucleo que se observa en las células benignas. En las células cancerígenas la cromatina tiende a ser más gruesa ya que forma grumos.\n","\n","**Normal_nucleoli**: Mide como de normal son los nucleolos. Los nucleolos son pequeñas estructuras que se ven en el núcleo. En las células normales, el nucléolo suele ser muy pequeño, si es que es visible. Los nucléolos se vuelven más prominentes en las células cancerígenas y, a veces, son múltiples.\n","\n","**Mitoses**: Mide la mitosis de las celulas. Esto es debido a que el cancer esencialmente es una enfermedad generada por una mitosis incontrolada.\n","\n","<br/>\n","<br/>\n","\n","Nuestra variable objetivo que es el diagnóstico será la siguiente (Viene categorizada con la etiqueta 2 o 4, para benigno y maligno respectivamente):\n","\n","**Diagnose**: Almacena si es benigno o maligno un tumor.\n","\n","<br/>\n","<br/>\n","\n","La función $F$ es una función desconocida que divide un conjunto de datos en cáncer maligno y benigno. Queremos aproximar una funcion $G$ que se acerque lo máximo posible a esta división, ya que estamos ante un problema de clasificación binaria.\n","\n","<br/>\n","\n","Para logar esto lo haremos mediante un conjunto de datos de entrenamiento que esté etiquetado correctamente con la clasificación de cáncer maligno y benigno, y mediante técnicas de aprendizaje automático que usaremos para aproximar nuestra función $G$.\n","\n","<br/>\n","\n","A continuación cargaremos los datos y procederemos a ver los datos que usaremos como $X$ y nuestra variable objetivo que es el diagnostico $Y$."],"metadata":{"id":"4FmwMkv1-stV"}},{"cell_type":"code","source":["import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"kEVMrgy4iysV","executionInfo":{"status":"ok","timestamp":1689078761197,"user_tz":-120,"elapsed":543,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["data_cols = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size',\n","        'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']\n","dataFrame = pd.read_csv(\"https://consigna.ugr.es/download.php?token=b0d2020e-3369-43ea-bf8e-64256532735c&files_ids=36615\", header = None)\n","dataFrame.columns = data_cols"],"metadata":{"id":"g4Zwc9q0cj0F","executionInfo":{"status":"error","timestamp":1689078763198,"user_tz":-120,"elapsed":2004,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}},"outputId":"a3c6a671-da92-4836-b84c-f96d7c5d41ff","colab":{"base_uri":"https://localhost:8080/","height":276}},"execution_count":2,"outputs":[{"output_type":"error","ename":"ParserError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-a3c337cfcb33>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data_cols = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size',\n\u001b[1;32m      2\u001b[0m         'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://consigna.ugr.es/download.php?token=b0d2020e-3369-43ea-bf8e-64256532735c&files_ids=36615\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 40, saw 2\n"]}]},{"cell_type":"markdown","source":["A continuación podemos ver los datos completamente cargados desde el archivo. Estos datos son los que hemos especificado anteriormente incluyendo la variable **Sample code number** que es la que hemos mencionado como que es un identificador y no es una variable predictiva."],"metadata":{"id":"9K2CtcV9leYa"}},{"cell_type":"code","source":["dataFrame"],"metadata":{"id":"eilJ1EXAmdAU","executionInfo":{"status":"aborted","timestamp":1689078763198,"user_tz":-120,"elapsed":22,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esta será la columna donde se guarda nuestra variable objetivo $Y$ que como podemos apreciar tiene valores binarios pero son 2 y 4 en lugar de 0 y 1. Una vez separado la parte de train y test podremos comenzar a trabajar en el preprocesado de las variables para tener unos valores más intuitivos."],"metadata":{"id":"TfL4ebP8Wdpk"}},{"cell_type":"code","source":["dataFrame['Class']"],"metadata":{"id":"UKfS2rciWi6x","executionInfo":{"status":"aborted","timestamp":1689078763199,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dada la información que nos aporta la documentación del problema. Nos dice que tiene clases desbalanceadas por lo que vamos a proceder a verlo en el siguiente esquema.\n","\n","El siguiente esquema simplemente muestra dos columnas una para el número de valores de muestras de tumores benignos que tenemos en el conjunto de datos y otra columna que muestra el número de muestras de tumores malignos en el conjunto de datos."],"metadata":{"id":"R4qxHkIFXCAU"}},{"cell_type":"code","source":["plt.figure(figsize=(8,5))\n","plt.bar([0, 1], [len(dataFrame.index[dataFrame[dataFrame.columns[-1]] == 2].tolist()), len(dataFrame.index[dataFrame[dataFrame.columns[-1]] == 4].tolist())], tick_label =  ['Benigno', 'Maligno'])\n","plt.title('Numero de ejemplos por clase')\n","plt.show()"],"metadata":{"id":"J2vGZePGAWIn","executionInfo":{"status":"aborted","timestamp":1689078763199,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Número de muestras exacto de cada una: \")\n","dataFrame[dataFrame.columns[-1]].value_counts()"],"metadata":{"id":"d_JCOVFZKBfF","executionInfo":{"status":"aborted","timestamp":1689078763199,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como podemos ver tenemos una proporción cercana al 66-33 que es un ratio no cosiderado como desbalanceado, de hecho este ratio es conocido como levemente desbalanceado (slighly imbalanced). Podemos dar lugar a pensar que en este caso la predicción de un modelo que niega siempre no tiene por qué ser tan buena. Lo decimos ya que en la P3 el problema de clasificación era un 90-10 por lo que siempre hacia una predicción negativa y había un accuracy muy alto, pero, ¿donde esta el aprendizaje ahí?\n","\n","Información desbalanceado leve:\n","- https://machinelearningmastery.com/what-is-imbalanced-classification/\n","- https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18"],"metadata":{"id":"mQFfsjCdXjme"}},{"cell_type":"markdown","source":[" A continuación lo que hacemos es generar el rango de valores que después usaremos en la función ONE HOT ENCODING ya que entrenaremos al algoritmo con este rango para que, dado que nos dicen que todas las variables (excepto la objetivo) tienen el rango 1-10 podemos suponer por ejemplo una caracteristica de $X$ que en todo su dominio pueda no tener un valor pero que este si esté en test. Basicamente lo que quiero decir es que si hay un valor muy poco frecuente supongamos que es el \"1\" y solo hay una muestra con ese valor y ese valor cae en test podria pasar que si aplicamos ONE HOT ENCODING sobre la columna del conjunto de entrenamiento solo obtengamos el dominio 2-10 mientras que en test si que tendriamos el dominio completo 1-10 lo cual conllevaría a un error de dimensionalidad entre los dos conjuntos. Por ello aplicaremos el ONE HOT ENCODING entrenandolo con este rango dando lugar así con total seguridad a tener el dominio completo de la variable en ambos conjuntos.\n","\n","<br/>\n","<br/>\n","\n"," Ahora expliquemos que es lo que hace ONE HOT ENCODING:\n"," One Hot Encoding asigna una columna binaria a cada categoría única en la variable categórica original. Cada columna binaria representa una categoría específica y toma el valor 1 si la observación pertenece a esa categoría y 0 en caso contrario. De esta manera, se crea una representación numérica que captura la información de la variable categórica sin asignarle un orden o relación numérica arbitraria.\n","\n","Por ejemplo, supongamos que tienes una variable categórica \"Color\" con tres categorías únicas: Rojo, Verde y Azul. Después de aplicar el One Hot Encoding, la variable \"Color\" se transformaría en tres columnas binarias: \"Rojo\", \"Verde\" y \"Azul\". Si una muestra tiene el color Rojo, la columna \"Rojo\" tomará el valor 1 y las columnas \"Verde\" y \"Azul\" tomarán el valor 0.\n","\n","One Hot Encoding permite que los algoritmos de aprendizaje automático utilicen la información de las variables categóricas de manera adecuada, ya que los valores numéricos generados reflejan la presencia o ausencia de una categoría en particular."],"metadata":{"id":"eyaJMbVyYHSE"}},{"cell_type":"code","source":["# Rango para aplicar one hot encoding como sabemos que todas van de 1-10 ponemos nosotros el rango\n","# y si hubiese un outlier (por ejemplo un 12) nos daría el error de encoding porque no podría codificar ese valor\n","values = np.arange(1,11)\n","RANGE = []\n","for i in values:\n","  RANGE.append([i])"],"metadata":{"id":"FP5BU8nMCF-F","executionInfo":{"status":"aborted","timestamp":1689078763199,"user_tz":-120,"elapsed":22,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Informandonos sobre cual es la mejor regla para partir un conjunto train/test vemos que no hay una regla que diga que tamaño es mejor o peor para dividir los datos en train y test pero lo que si hemos visto es que lo que más se hace es dividirlo en ratios de 80-20 y 70-30 que suelen ser los que mejor funcionan.\n","\n","Aún así en numerosos articulos de machine learning se opta por una division de la siguiente forma para cross validation donde el 15% es el tamaño del test y el resto train 85% que a su vez cuando lo hagamos en una validacion cruzada tendremos un tamaño de test_val cercano al 15%. (85/15 = 17 $\\simeq$ 15)\n","\n","Para la division del conjunto de datos en train y test usaremos la funcion de sklearn train_test_split que recibe los parametros:\n","1. El primer parámetro de la función recibe $X$ que es el conjunto de datos.\n","2. El segundo parámetro  después la $Y$\n","3. El tercer parámetro que recibe es el % de muestras que formará el test que en nuestro caso sera 0.15 (15%) size para ver en que cantidad vamos a dividir el conjunto (en nuestro caso será 0.15 para que el test sea $\\simeq$ 15%)\n","4. El cuarto parámetro será la semilla, random_state que fijaremos para que siempre nos de los mismos conjuntos independientemente de la ejecucion.\n","\n"],"metadata":{"id":"9fMgePWmCP-f"}},{"cell_type":"markdown","source":["# **PREPROCESAMIENTO Y TRATADO DE DATOS**"],"metadata":{"id":"2cFBFHsAUQMh"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split( dataFrame[dataFrame.columns[1:-1]], dataFrame[dataFrame.columns[-1]], test_size=0.15, random_state=42)"],"metadata":{"id":"dAPtS-QwCTNH","executionInfo":{"status":"aborted","timestamp":1689078763200,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Una vez ya tenemos el conjunto de train y test podemos ponernos a trabajar sobre el preprocesamiento de las variables del problema. En primer lugar vamos a tratar el problema de las variables faltantes. En la documentación oficial ya se nos avisa que hay 16 datos faltantes y que vienen marcados con un simbolo tal que \"?\" pero no sabemos nada más. Para ver donde se encuentra esta variable lo que vamos a hacer es mostrar los valores unicos de todas las columnas de esta forma veremos donde se encuentra el valor \"?\"."],"metadata":{"id":"33e6zdVJmeCP"}},{"cell_type":"code","source":["for column in X_train.columns:\n","  if X_train[X_train[column] == '?'].shape[0] > 0:\n","    print(column, \"tiene\", str(X_train[X_train[column] == '?'].shape[0]), \"datos faltantes en X_train\")\n","  if X_train[X_train[column] == '?'].shape[0] > 0:\n","    print(column, \"tiene\", str(X_test[X_test[column] == '?'].shape[0]), \"datos faltantes en X_test\")"],"metadata":{"id":"Bml3pz3PpO3J","executionInfo":{"status":"aborted","timestamp":1689078763200,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como podemos ver los valores faltantes solo los tenemos en la columna de **Bare Nuclei** por lo cual se nos facilita el trabajo ya que solo tendremos que tratar con una variable de la muestra.\n","\n","Para lidiar con los datos faltantes lo que haremos será lo siguiente como es una variable categorica obtendremos la distribución de probabilidad, esto lo haremos obteniendo la moda de cada uno de los valores y la dividiremos entre el total de muestras, de esta forma obtendremos la distribución de probabilidad y entre todas deben sumar 1.\n","\n","Para obtener \"n\" valores aleatorios de la distribución que hemos obtenido lo haremos mediante la función que nos brinda numpy llamada random.choice. Esta función lo que hace es devolvernos un aleatorio a partir de los valores de las variables, que son el primer parametro de la función y la distribución de probabilidad. En este caso le pasaremos en el último parámetro el número de valores faltantes y obtendremos \"n\" valores aleatorios que se lo asociaremos a la celda que tiene \"?\". De esta forma ya tendremos solucionado el problema de los valores faltantes.\n"],"metadata":{"id":"3sYD5aJUtpkJ"}},{"cell_type":"code","source":["moda = X_train[X_train['Bare Nuclei'] != '?']['Bare Nuclei'].astype(int)\n","moda = moda.value_counts()\n","\n","p_vals = moda.sort_index() / (X_train.shape[0] - X_train[X_train['Bare Nuclei'] == '?'].shape[0])\n","\n","values = np.random.choice(np.arange(1,11), p=p_vals, size = X_train[X_train['Bare Nuclei'] == '?'].shape[0])\n","X_train.loc[X_train[X_train['Bare Nuclei'] == '?'].index, 'Bare Nuclei'] = values\n","\n","values = np.random.choice(np.arange(1,11), p=p_vals, size = X_test[X_test['Bare Nuclei'] == '?'].shape[0])\n","X_test.loc[X_test[X_test['Bare Nuclei'] == '?'].index, 'Bare Nuclei'] = values\n","\n","column = 'Bare Nuclei'\n","X_train[column] = X_train[column].astype(int)\n","X_test[column] = X_test[column].astype(int)\n","\n","X_train[column] = X_train[column].astype('Int64')\n","X_test[column] = X_test[column].astype('Int64')"],"metadata":{"id":"-MZrf7-urMC1","executionInfo":{"status":"aborted","timestamp":1689078763200,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Una vez ya terminado con las variables faltantes otra cosa que haremos será cambiar el dominio de la variable objetivo ya que ahora mismo tiene el dominio 2,4 y preferimos cambiarlo a un dominio más conocido como es 0,1 para benigno y maligno respectivamente."],"metadata":{"id":"CVIvxnPMvuTq"}},{"cell_type":"code","source":["y_train[y_train == 2] = 0\n","y_train[y_train == 4] = 1\n","y_test[y_test == 2] = 0\n","y_test[y_test == 4] = 1"],"metadata":{"id":"DnpXFG_qwkdA","executionInfo":{"status":"aborted","timestamp":1689078763201,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Una vez ya hecho esto seguimos el preprocesamiento de los datos por los outliers.\n","\n","En general, los outliers no se aplican directamente a variables categóricas de la misma manera que se aplican a variables numéricas. Los outliers están más relacionados con valores extremos o inusuales en una distribución numérica.\n","\n","Sin embargo, en el contexto de variables categóricas, es posible que existan categorías poco comunes o inesperadas que se consideren atípicas. En este sentido, se puede hablar de categorías raras o inusuales como \"outliers\" en el contexto de variables categóricas. Estas categorías pueden tener una frecuencia muy baja en comparación con las demás categorías o pueden ser inesperadas en función del dominio del problema.\n","\n","Es importante tener en cuenta que la detección de outliers en variables categóricas puede depender del contexto y del problema en particular. Lo que se considera un outlier en una variable categórica puede variar según la interpretación del dominio del problema y los conocimientos previos.\n","\n","En nuestro caso un outlier lo interpretaremos como un valor fuera del rango que se nos da en la documentación que es [1:10]. La forma en la que veremos la existencia de outliers será simplemente ver el valor máximo y mínimo de cada una de las variables, si ninguna se va por encima de 10 o por debajo de 1 estaremos dentro del dominio correcto (son numeros enteros no puede existir una categoría 1.5)\n","\n","También explicaremos el por qué lo hemos aplicado al test también y es que la decisión de eliminar o no los outliers en el conjunto de prueba depende del contexto y del objetivo del análisis de datos. La decision la podemos tomar teniendo en cuenta lo siguiente:\n","\n","1. Consistencia con el conjunto de entrenamiento: Si previamente eliminamos outliers del conjunto de entrenamiento, puede ser razonable aplicar la misma estrategia al conjunto de prueba para mantener la consistencia en el procesamiento de los datos. Esto puede evitar la introducción de sesgos y garantizar una comparación adecuada entre los conjuntos.\n","\n","2. Representatividad de los outliers: Hay que considerar si los outliers en el conjunto de prueba son realmente valores atípicos o si representan casos reales que pueden existir en situaciones del mundo real (en nuestro caso esta acotado no puede existir o no debe existir ningun valor fuera de este).\n","\n","En general, se recomienda tener precaución al eliminar outliers, especialmente en el conjunto de prueba, ya que esto puede introducir sesgos y afectar la representatividad de los datos.\n","\n","Por ello lo que haremos en este caso será mirar si hay outliers tanto en train como en test y cambiarlos de la misma forma que lo hacemos en train."],"metadata":{"id":"L1ImK1fIxKN8"}},{"cell_type":"code","source":["for column in X_train.columns:\n","  print(\"****\", column, '****')\n","  print(\"EN TRAIN --> Máximo\", X_train[column].max(), \";\", \"Mínimo\", X_train[column].min())\n","  print(\"EN TEST --> Máximo\", X_test[column].max(), \";\", \"Mínimo\", X_test[column].min())\n","  print()\n","\n","print('**** OBJETIVO ****')\n","print(\"EN TRAIN --> Máximo\", y_train.max(), \";\", \"Mínimo\", y_train.min())\n","print(\"EN TEST --> Máximo\", y_test.max(), \";\", \"Mínimo\", y_test.min())\n","print()"],"metadata":{"id":"7rac6ir-xJrM","executionInfo":{"status":"aborted","timestamp":1689078763201,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora ya si que vamos a aplicar ONE HOT ENCODING. El problema de esto es que aumentaremos la dimensionalidad en 10 por cada una de las variables que tenemos ya que el rango de cada una va de 1-10 (aumentamos la dimensionalidad de VC). Ya hemos explicado anteriormente lo que hace ONE HOT ENCODING por lo que ahora procedemos a entrenarlo llamando al metodo \"fit\" esto entrenará a nuestro encoder para saber que ha de hacer con cada una de las variables.\n","\n","Antes de seguir vamos a explicar el parametro que le hemos puesto a la instancia de OneHotEncoder llamado \"handle_unkown\". Este parámetro lo que hace es decirle a nuestro encoder lo que debe hacer cuando se encuentra con un dato no conocido. El parámetro puede tomar distintos valores como \"error\" o \"ignore\" en el último caso no da ningun tipo de error. Nosotros escogeremos 'error' ya que si se encontrase un valor fuera del dominio no ejecutaria por completo y abortaría. Aun así no debería de haber ningún problema debido a que hemos revisado anteriormente que esto no ocurra.\n","\n","Iremos columna por columna aplicandole la transformación pertinente que lo que hará es si tiene una variable \"X\" con 10 valores creará variables binarias tal que \"x1\", \"x2\" ... \"x_10\". Por lo cuál una vez aplicada la transformación ya no serán necesarias las columnas primogénitas.\n","\n","Lo que se hace en el código es ir montando un DataFrame identico al original pero que en lugar de tener la variable \"x\" con valores 1-10 tendrá las variables \"x1\"-\"x_n\" como variables binarias.\n","\n","Lo aplicamos tanto para train como para test (nunca usando datos de test como entrenamiento del encoder) ya que necesitamos que el test haya pasado por las mismas transformaciones que por las que pasó el conjunto de train."],"metadata":{"id":"NC6lCh56HBzm"}},{"cell_type":"code","source":["# Aplicamos one hot enconding a todas las variables categóricas (En este problema todas las etiquetas)\n","from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder(handle_unknown='error')\n","\n","enc.fit(RANGE)\n","\n","X_train_R = pd.DataFrame()\n","X_test_R = pd.DataFrame()\n","R_variables_new_cols = []\n","for column in X_train.columns:\n","  for i in range(len(RANGE)):\n","    R_variables_new_cols.append(column + \"_\" + str(i + 1))\n","  X_train_R = pd.concat([X_train_R, pd.DataFrame(enc.transform(X_train.loc[:,column].values.reshape(-1,1)).toarray())], axis = 1)\n","  X_test_R = pd.concat([X_test_R, pd.DataFrame(enc.transform(X_test.loc[:,column].values.reshape(-1,1)).toarray())], axis = 1)\n","\n","X_train_R.columns = R_variables_new_cols\n","X_train_R = X_train_R.reset_index(drop = True)\n","\n","X_test_R.columns = R_variables_new_cols\n","X_test_R = X_test_R.reset_index(drop = True)\n","\n","X_train = X_train_R.copy()\n","X_test = X_test_R.copy()"],"metadata":{"id":"JkQVlRwhCZMa","executionInfo":{"status":"aborted","timestamp":1689078763201,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hemos aumentado de dimension cada una de las variables (9) por 10 valores que pueden tomar (9*10). Si antes teníamos una dimensión de 9 (1 por cada variable usada para la predicción) ahora tendremos 90 debido a la codificación de cada una de ellas."],"metadata":{"id":"TE7Kh-TfFc0u"}},{"cell_type":"markdown","source":["En cuanto al uso de PCA o FA (para la reducción de la dimensionalidad VC) en este problema tenemos que tener en cuenta que es un problema que solo consta de variables categóricas y que el Análisis de Componentes Principales (PCA) y el Análisis Factorial (FA) son técnicas de reducción de dimensionalidad ampliamente utilizadas en problemas con variables numéricas continuas. Por lo que no recomendaremos su uso para este tipo de problemas por las siguientes razones:\n","\n","1. Naturaleza de las variables categóricas: Las variables categóricas representan categorías o grupos discretos, y no tienen una relación de orden o magnitud inherente. PCA y FA se basan en la covarianza o la matriz de correlación de las variables, y asumen que las variables son numéricas y continúas.\n","\n","2. Escalado y distancias: PCA y FA implican la estandarización de las variables para asegurar que todas tengan la misma escala. En el caso de las variables categóricas, no existe una medida de distancia adecuada para calcular la covarianza o la correlación. No tiene sentido estandarizar variables categóricas en la misma forma que las variables numéricas.\n","\n","3. Interpretación de los componentes/factores: En PCA y FA, los componentes o factores resultantes se interpretan como combinaciones lineales de las variables originales. Sin embargo, en presencia de variables categóricas, no hay una manera directa de interpretar la combinación lineal de categorías.\n","\n","Por estas razones en nuestro problema no usaremos ninguna de las tecnicas mencionadas ya que no tendría sentido su uso.\n","\n","Debido a que tenemos un problema con variable categóricas tampoco es necesario en nuestro caso ningún tipo de normalizacion (codificacion != normalización)."],"metadata":{"id":"mznyzv7MHHpd"}},{"cell_type":"markdown","source":["\n","# **MODELOS DE APRENDIZAJE ELEGIDOS**"],"metadata":{"id":"6hqATau0ohUG"}},{"cell_type":"markdown","source":["Los modelos que vamos a implementar durante la realización de la práctica van a ser RandomForest, SVM (sin kernel lineal) y Regresión Logistica.\n","La **Regresión Logistica** la hemos escogido ya que necesitamos implementar un modelo lineal y compararlo con dos modelos no lineales. Lo interesante de usar este modelo a diferencia de otros como el PLA-POCKET es que es eficiente computacionalmente y se puede implementar fácilmente además de que funciona bien en conjuntos de datos linealmente separables y no linealmente separables, ya que puede aprender fronteras de decisión flexibles a través de la función sigmoide.\n","\n","La elección de **RandomForest** y **SVM** es dado a que hemos buscado distintos articulos que tratan este tema y los más elegidos son estos (cuando no se trata de imagenes ya que hay muchos dataset de cancer que están sobre imágenes) dando unos buenos resultados sobre los distintos conjuntos de Breast Cancer Datasets que se encuentran en la web incluido el nuestro.\n","\n","\n","<hr/>\n","\n","Información:\n","\n","https://pubmed.ncbi.nlm.nih.gov/26409558/\n","https://www.researchgate.net/publication/365615067_Comparison_of_machine_learning_models_for_breast_cancer_diagnosis\n","\n"],"metadata":{"id":"sspEqRiWAl-B"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression"],"metadata":{"id":"cwxZ6AmOojVL","executionInfo":{"status":"aborted","timestamp":1689078763201,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **FUNCIONES DE PERDIDA Y METRICAS DE ERROR**"],"metadata":{"id":"ysN8ACPX9wur"}},{"cell_type":"markdown","source":["Vamos a mostrar una imagen de como se distribuye la matriz de confusión de un modelo para que tengamos un contexto a la hora de que expliquemos las distintas formulas para cada una de las métricas de error.\n","\n","La matriz de confusión es una tabla que muestra el número de predicciones correctas e incorrectas realizadas por un modelo clasificador en cada una de las clases.\n","\n","La interpretación de cada celda en la matriz es la siguiente:\n","\n","* Verdadero positivo (True Positive, TP): El modelo predijo correctamente una muestra positiva como positiva.\n","* Falso negativo (False Negative, FN): El modelo predijo incorrectamente una muestra positiva como negativa.\n","* Falso positivo (False Positive, FP): El modelo predijo incorrectamente una muestra negativa como positiva.\n","* Verdadero negativo (True Negative, TN): El modelo predijo correctamente una muestra negativa como negativa."],"metadata":{"id":"ksCn2lErGJCz"}},{"cell_type":"markdown","source":["![aaa.png](data:image/png;base64,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)"],"metadata":{"id":"Opf-DBnR9-Ui"}},{"cell_type":"markdown","source":["A continuación vamos a explicar las métricas de error que hemos considerado más oportunas para la realización de este problema:\n","\n","**Recall** (Sensibilidad): El recall, tambien conocido como sensibilidad o tasa de verdaderos positivos, es una métrica utilizada en problemas de clasificación para evaluar la capacidad del modelo para identificar correctamente las muestras positivas. Mide la proporcion de verdaderos positivos sobre el total de muestas positivas en los datos reales. Una puntuación alta de recall indica que el modelo tiene una alta capacidad para detectar correctamente las muestras positivas en los datos reales, lo cual es especialmente importante en casos donde la identificación de positivos es critica, como pasa en nuestro problema.\n","\n","En nuestro caso, recall es importante en la predicción de cáncer debido a su capacidad para capturar la proporción de casos positivos correctamente identificados por el modelo. Un alto recall indica que el modelo tiene una baja tasa de falsos negativos, lo que implica que hay una menor probabilidad de clasificar erróneamente a un paciente con cáncer como negativo. Esto es crítico para evitar casos de cancer que no se detecten, ya que podría retrasar el tratamiento y tener un impacto negativo en la salud del paciente.\n","\n","Se calcula de la siguiente forma:\n","\n","$$Recall = \\frac{TP}{(TP+FN)}$$\n","<br/>\n","\n","**Accuracy** (Precisión): La precisión es una métrica común utilizada en problemas de clasificación para evaluar el rendimiento general del modelo. Mide la proporción de predicciones correctas sobre el total de predicciones realizadas por el modelo. Es calculada dividiendo el número de predicciones correctas por el número total de predicciones. Una puntuación de precisión alta indica un modelo que realiza un buen trabajo en la clasificación correcta de las muestras.\n","\n","$$Accuracy = \\frac{TP + TN}{(TP+FP+TN+FN)}$$\n","\n","<br/>\n","\n","\n","**F1-Score**: El F1-Score es una medida de la precisión y recall combinadas. Combina la precisión y el recall en una sola métrica para proporcionar una evaluación más completa del rendimiento del modelo. El F1-Score es útil cuando hay un desequilibrio entre las clases en el conjunto de datos. Un F1-Score alto indica un modelo que tiene un equilibrio entre la precisión y el recall en la clasificación.\n","\n","$$F1\\_Score = 2*\\frac{(Precision*Recall)}{(Precision+Recall)}$$\n","<br/>\n","\n","**AUC-ROC** (Área bajo la curva de Característica Operativa del Receptor): es una métrica que mide la calidad general de un modelo de clasificación binaria al evaluar su capacidad para discriminar entre las clases positivas y negativas. Un mayor valor de AUC-ROC indica un mejor rendimiento del modelo, mientras que un valor de 0.5 indica un rendimiento comparable al azar.\n","\n","<br/>\n","\n","Para finalizar vamos a decir que nuestras elecciones las basaremos siempre sobre todo fijandonos en la métrica RECALL debido a lo que hemos comentado de que queremos evitar los falsos negativos debido a que dar un diagnostico negativo a una persona que es positiva puede ser crucial.\n"],"metadata":{"id":"wb4nGy8-oio9"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score as F1\n","from sklearn.metrics import accuracy_score as ACC\n","from sklearn.metrics import roc_auc_score as ROC\n","from sklearn.metrics import recall_score as RECALL"],"metadata":{"id":"5wj4o6EFC6Ef","executionInfo":{"status":"aborted","timestamp":1689078763202,"user_tz":-120,"elapsed":24,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Las funciones de pérdida de cada uno de nuestros algoritmos escogidos las explicaremos a continuación:"],"metadata":{"id":"LSkv0O5a_a_O"}},{"cell_type":"markdown","source":["<H2> RANDOM FOREST </H2>\n","\n","En cuanto a las funciones de pérdida de cada uno de los modelos que vamos a implementar en primer lugar veremos RandomForest:\n","\n","A diferencia de muchos otros algoritmos, como las redes neuronales o los modelos lineales, los Random Forest no se basan en una función de pérdida específica durante el entrenamiento.\n","\n","En **Random Forest** , cada árbol individual dentro del ensamble se entrena de forma independiente utilizando una técnica llamada Bootstrap Aggregating o \"bagging\". Cada árbol se construye utilizando una muestra aleatoria con reemplazo del conjunto de entrenamiento original. Luego, las predicciones finales se obtienen promediando o tomando el voto de las predicciones individuales de todos los árboles.\n","\n","Dado que Random Forest no optimiza una función de pérdida específica durante el entrenamiento, no hay una función de pérdida predefinida asociada con este algoritmo. La evaluación de la calidad del modelo Random Forest se realiza a través de métricas específicas según el problema que se esté abordando, como precisión, exactitud, F1-score o error cuadrático medio (MSE), dependiendo si es un problema de clasificación o regresión.\n","\n","<hr/>\n","\n","<H2> SVM </H2>\n","\n","En el caso de las **máquinas de vectores de soporte (SVM)** que es otro de los modelos que vamos a implementar para este problema de clasificación, la función de pérdida utilizada comúnmente es la función de pérdida hinge loss.\n","\n","La función de pérdida de bisagra se define de la siguiente manera para un ejemplo de entrenamiento con una etiqueta verdadera (1 para clase positiva y 0 para clase negativa) y una predicción del SVM denotada como f(x):\n","\n","$$L(y, f(x)) = max(0, 1 - y * f(x))$$\n","\n","En esta función de pérdida, si el producto y * f(x) es mayor o igual a 1, el resultado es cero, lo que indica que la predicción es correcta y no se incurre en pérdida. Si el producto es menor que 1, la pérdida es proporcional a la distancia entre la predicción y la separación óptima de la clase, lo que penaliza las clasificaciones incorrectas. Cuanto mayor sea la distancia, mayor será la pérdida.\n","\n","El objetivo del SVM es encontrar el hiperplano que minimice la suma de estas pérdidas y al mismo tiempo maximice el margen entre las clases. Esto se logra a través de la optimización convexa resolviendo un problema de programación cuadrática.\n","\n","<hr/>\n","\n","<H2> REGRESIÓN LOGISTICA </H2>\n","\n","En la **regresión logística (RL)** , la función de pérdida utilizada comúnmente es la función de pérdida logística, también conocida como entropía cruzada o log loss.\n","\n","Para un problema de regresión logística binaria, donde las etiquetas de clase son 0 o 1, la función de pérdida logística se define de la siguiente manera:\n","\n","$$ L(y, f(x)) = -[y * log(f(x)) + (1 - y) * log(1 - f(x))] $$\n","\n","En esta fórmula, \"y\" representa la etiqueta verdadera (0 o 1) y \"f(x)\" es la predicción del modelo de regresión logística para el ejemplo de entrenamiento. La función de pérdida logística compara la predicción \"f(x)\" con la etiqueta verdadera \"y\" y penaliza las predicciones incorrectas.\n","\n","Cuando \"y\" es 1, la función de pérdida se enfoca en la parte izquierda de la ecuación, donde se penaliza si la predicción \"f(x)\" es baja. Por otro lado, cuando \"y\" es 0, la función de pérdida se enfoca en la parte derecha de la ecuación, penalizando las predicciones altas. El objetivo es minimizar la función de pérdida global, lo que implica encontrar los parámetros del modelo que se ajusten mejor a los datos observados.\n"],"metadata":{"id":"wa7DWcKASwS_"}},{"cell_type":"code","source":["############################ FUNCION CROSS VALIDATION ############################\n","#\n","# Esta función lo que hace es hacer una cross validation usando stratifiedkfold.\n","# El uso de StratifiedKFold para hacer los distintos folds de una cross validation\n","# es debido a que hay un leve desbalanceo en los datos esta función hará que caigan\n","# en la misma proporción en cada uno de los folds las muestras de la clase levemente\n","# desbalanceada.\n","# Por cada uno de los folds calcularemos las métricas de error sobre el modelo que estemos\n","# evaluando.\n","# Los parámetros que recibe esta funcion son\n","#       * X_train --> es el conjunto de datos de entrenamiento\n","#       * y_train --> los valores objetivo por cada una de las muestras de entrenamiento\n","#       * model --> es un vector tal que [nombre, modelo] que contiene el modelo y el nombre del modelo a evaluar\n","#       * show_outputs --> es un booleano que nos indica si queremos mostrar las matrices de confusion por cada uno de los folds o no verlas.\n","# Return:\n","#      * devuelve todos y cada uno de los vectores que almacena el valor de la metrica tanto para entrenamiento como para test y en total\n","#      se devuelven 8 vectores (4 metricas * 2(test y train))\n","#\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix\n","\n","def own_cv(X_train, y_train, model, show_outputs):\n","\n","  index = 1\n","  accuracy_training = []\n","  accuracy_test = []\n","\n","  f1_score_trainig = []\n","  f1_score_test = []\n","\n","  roc_training = []\n","  roc_test = []\n","\n","  recall_training = []\n","  recall_test = []\n","\n","  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","  for train_index, test_index in skf.split(X_train, y_train):\n","\n","      x_train_fold, x_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n","      y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n","\n","      model[1].fit(x_train_fold, y_train_fold)\n","\n","      train_pred = model[1].predict(x_train_fold)\n","      test_pred = model[1].predict(x_test_fold)\n","\n","      accuracy_training.append(ACC(y_train_fold, train_pred))\n","      f1_score_trainig.append(F1(y_train_fold, train_pred))\n","      roc_training.append(ROC(y_train_fold, train_pred))\n","      recall_training.append(RECALL(y_train_fold, train_pred))\n","\n","      accuracy_test.append(ACC(y_test_fold, test_pred))\n","      f1_score_test.append(F1(y_test_fold, test_pred))\n","      roc_test.append(ROC(y_test_fold, test_pred))\n","      recall_test.append(RECALL(y_test_fold, test_pred))\n","\n","      if show_outputs == True:\n","        print(confusion_matrix(y_test_fold, test_pred))\n","        print()\n","\n","      index += 1\n","\n","\n","  if show_outputs == True:\n","    print(\"ACCURACY TRAIN: \", np.array(accuracy_training).mean())\n","    print(\"F1 TRAIN: \", np.array(f1_score_trainig).mean())\n","    print(\"ROC TRAIN: \", np.array(roc_training).mean())\n","    print(\"RECALL TRAIN: \", np.array(recall_training).mean())\n","    print()\n","    print(\"ACCURACY TEST_CV: \", np.array(accuracy_test).mean())\n","    print(\"F1 TEST_CV: \", np.array(f1_score_test).mean())\n","    print(\"ROC TEST_CV: \", np.array(roc_test).mean())\n","    print(\"RECALL TEST_CV: \", np.array(recall_test).mean())\n","\n","\n","  return accuracy_training, f1_score_trainig, roc_training, recall_training, accuracy_test, f1_score_test, roc_test, recall_test"],"metadata":{"id":"-VZmS8yiGER_","executionInfo":{"status":"aborted","timestamp":1689078763202,"user_tz":-120,"elapsed":24,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############################ FUNCION CV_TO_MODELS ############################\n","#\n","# Esta función lo que tratamos de hacer es recorrer un vector de modelos que le hemos pasado a\n","# la función y lo que hacemos es llamar a la funcion anterior por cada modelo y obteniendo las\n","# métricas y vamos juntandolas en un dataframe para guardar la información y después poder\n","# mostrarla en una gráfica\n","# Los parametros que recibe:\n","#     * models --> es un vector de modelos en el que el modelo viene representado por la siguiente notacion [nombre, modelo] por lo que\n","#                  el vector biene definido tal que [[nombre, modelo],[nombre, modelo]]\n","# Return:\n","#     * retorna 2 datasets,  uno para las metricas en train y otro para las metricas en test para todos los modelos que se encontraban\n","#     en el vector\n","\n","\n","def cv_to_models(models, X_train, y_train, show_outputs = False):\n","  df_accuracy_tr = pd.DataFrame()\n","  df_f1_tr = pd.DataFrame()\n","  df_roc_tr = pd.DataFrame()\n","  df_recall_tr = pd.DataFrame()\n","\n","  df_accuracy_te = pd.DataFrame()\n","  df_f1_te = pd.DataFrame()\n","  df_roc_te = pd.DataFrame()\n","  df_recall_te = pd.DataFrame()\n","\n","  for model in models:\n","      print(\"************ \", model[0], \" ************\")\n","      scores_acc_tr, scores_f1_tr, scores_roc_tr, scores_recall_tr, scores_acc_tes, scores_f1_tes, scores_roc_tes, scores_recall_tes = own_cv(X_train, y_train, model, show_outputs)\n","\n","      df_accuracy_tr = pd.concat([df_accuracy_tr, pd.DataFrame(scores_acc_tr)], axis = 1)\n","      df_f1_tr = pd.concat([df_f1_tr, pd.DataFrame(scores_f1_tr)], axis = 1)\n","      df_roc_tr = pd.concat([df_roc_tr, pd.DataFrame(scores_roc_tr)], axis = 1)\n","      df_recall_tr = pd.concat([df_recall_tr, pd.DataFrame(scores_recall_tr)], axis = 1)\n","\n","      df_accuracy_te = pd.concat([df_accuracy_te, pd.DataFrame(scores_acc_tes)], axis = 1)\n","      df_f1_te = pd.concat([df_f1_te, pd.DataFrame(scores_f1_tes)], axis = 1)\n","      df_roc_te = pd.concat([df_roc_te, pd.DataFrame(scores_roc_tes)], axis = 1)\n","      df_recall_te = pd.concat([df_recall_te, pd.DataFrame(scores_recall_tes)], axis = 1)\n","\n","      print()\n","\n","  df_to_plot_tr = pd.DataFrame([df_accuracy_tr.mean().values, df_f1_tr.mean().values, df_roc_tr.mean().values, df_recall_tr.mean().values])\n","  df_to_plot_te = pd.DataFrame([df_accuracy_te.mean().values, df_f1_te.mean().values, df_roc_te.mean().values, df_recall_te.mean().values])\n","\n","  model_cols = []\n","  for model in models:\n","    model_cols.append(model[0])\n","\n","\n","  df_to_plot_te.columns = df_to_plot_tr.columns = model_cols\n","\n","  df_to_plot_te.index = df_to_plot_tr.index = [\"ACCURACY\", \"F1 SCORE\", \"AUC-ROC\", \"RECALL\"]\n","\n","  return df_to_plot_tr, df_to_plot_te\n"],"metadata":{"id":"9hPfTbqWGFqs","executionInfo":{"status":"aborted","timestamp":1689078763202,"user_tz":-120,"elapsed":23,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","##### FUNCIÓN QUE USAREMOS PARA MOSTRAR LAS MÉTRICAS Y SU DESEMPEÑO POR CADA MODELO #####\n","\n","def plot_performance(df_metrics, name, n_metrics = 4):\n","  x = np.arange(df_metrics.shape[0])  # the label locations\n","  width = 0.15  # the width of the bars\n","  multiplier = 0\n","\n","  dict_metrics = df_metrics.to_dict('list')\n","\n","  fig, ax = plt.subplots(figsize=(12,6))\n","\n","  for attribute, measurement in dict_metrics.items():\n","      #print(attribute, \"-\"+measurement+\"-\")\n","      offset = width * multiplier\n","      rects = ax.bar(x + offset, np.round(np.array(measurement),2), width, label=attribute)\n","      ax.bar_label(rects, padding=3)\n","      multiplier += 1\n","\n","  # Add some text for labels, title and custom x-axis tick labels, etc.\n","  ax.set_ylabel('Value')\n","  ax.set_title('Performance in ' + name)\n","  ax.set_xticks(x + width * max(0, 0.5 * (n_metrics - 1)), df_metrics.index)\n","  ax.legend(loc='upper left', ncols=3)\n","  ax.set_ylim([0, 1.2])\n","\n","  plt.show()"],"metadata":{"id":"c4bcdcPyGLd6","executionInfo":{"status":"aborted","timestamp":1689078763203,"user_tz":-120,"elapsed":24,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **BUSQUEDA Y OPTIMIZACIÓN DE PARÁMETROS PARA EL MODELO RANDOM FOREST**\n"],"metadata":{"id":"Lu5LuSpUpBnz"}},{"cell_type":"markdown","source":["RANDOM FOREST PARAMS, a continuación comentaremos sobre los parámetros usados en el clasificador Random Forest:\n","\n","> **n_estimators** (int, default = 100): Es el número de árboles en el bosque. Controla la cantidad de árboles de decisión utilizados en el clasificador de Random Forest.\n","\n","> **criterion** ({'gini', 'entropy', 'log_loss'}, default = 'gini'): Especifica la función para medir la calidad de una división en un árbol de decisión. Puede ser \"gini\" para el índice de Gini o \"entropy\" para la ganancia de información.\n","\n","> **max_depth** (int, default = None): Es la profundidad máxima de los árboles de decisión. Controla la profundidad máxima de cada árbol en el bosque. El valor predeterminado es None, lo que significa que los árboles se expandirán hasta que todas las hojas sean puras o hasta que todas las hojas contengan menos de min_samples_split muestras.\n","\n","> **min_samples_split** (int or float, default = 2): Es el número mínimo de muestras requeridas para dividir un nodo interno en un árbol de decisión. Si una división no tiene suficientes muestras, se detiene la construcción del árbol.\n","\n","> **min_samples_leaf** (int or float, default = 1): Es el número mínimo de muestras requeridas en una hoja de un árbol de decisión. Si una hoja tiene menos muestras que min_samples_leaf, no se realizará una división adicional y se detendrá la construcción del árbol.\n","\n","> **min_weight_fraction_leaf** (float, default = 0.0): Es similar a min_samples_leaf, pero expresado como una fracción del número total de muestras en lugar de un número entero. Puede ser utilizado para dar más peso a ciertas muestras.\n","\n","> **max_features** ({'sqrt', 'log2', None} int or float, default = 'sqrt'): Especifica el número de características a considerar al buscar la mejor división en un árbol de decisión. Puede ser un número entero, un porcentaje o una cadena.\n","\n","> **max_leaf_nodes** (int, default = None): Especifica el número máximo de nodos hoja en un árbol de decisión. Controla la cantidad máxima de nodos hoja que se pueden crear.\n","\n","> **min_impurity_decrease** (float, default = 0.0): Especifica la cantidad mínima de reducción de impureza requerida para realizar una división en un árbol de decisión. Una división solo se realizará si la reducción de impureza supera este valor. El valor predeterminado es 0. La ecuacion es la siguiente:\n","N_t / N * (impurity - N_t_R / N_t * right_impurity\n","                    - N_t_L / N_t * left_impurity)\n","\n","> **bootstrap** (bool, default = True): Es un booleano que indica si se debe realizar el muestreo con reemplazo (bootstrap) al construir árboles en el bosque. Si es True, se utilizará el muestreo bootstrap. Si es False, se utilizará todo el conjunto de datos.\n","\n","> **oob_score** (bool, default = False): Es un booleano que indica si se debe calcular el puntaje \"out-of-bag\" (oob). Si es True, el puntaje oob se calcula durante el ajuste y se almacena en el atributo \"oob_score_\".\n","\n","> **n_jobs** (int, default = None): Especifica el número de trabajos en paralelo para ejecutar durante el ajuste y la predicción. Puede ser un número entero para indicar el número exacto de trabajos o -1 para utilizar todos los procesadores disponibles.\n","\n","> **random_state** (int, RandomState instance or None, default = None): Controla la generación de números pseudoaleatorios para mezclar los datos en el cálculo de estimaciones de probabilidad. Se ignora cuando probability es False. Puedes pasar un número entero para obtener una salida reproducible en llamadas de función múltiples.\n","\n","> **verbose** (bool, default = False): Es un booleano que indica si se debe habilitar la salida detallada durante el ajuste.\n","\n","> **warm_start** (bool, default = False): Es un booleano que indica si se deben utilizar los coeficientes anteriores como inicialización para el ajuste de la siguiente llamada a fit. Esto permite el ajuste incremental.\n","\n","> **class_weight** (dict or 'balanced', default = None): Si no se proporciona, todas las clases se suponen que tienen peso uno. 'balanced' ajusta automáticamente los pesos de las clases de forma inversamente proporcional a las frecuencias de clase en los datos de entrada n_muestras / (n_clases * np.bincount(y)).\n","\n","> **ccp_alpha** (non-negativa float, default = 0.0): Es un parámetro de poda utilizado para la poda de complejidad mínima de coste (CCP). Controla la cantidad de poda aplicada a los árboles de decisión. Valores más altos aumentan la poda.\n","\n","> **max_samples** (int or float, default = None): Especifica el número de muestras a muestrear para entrenar cada árbol individual en el bosque aleatorio. Puede ser un número entero o un valor en el rango (0, 1] para representar una fracción de las muestras totales. El valor predeterminado es None, lo que significa que se utiliza todo el conjunto de datos.\n"],"metadata":{"id":"S1irMbumGKjq"}},{"cell_type":"markdown","source":["En primer lugar vamos a probar con el parámetro de los estimadores, el mejor parámetro lo iremos buscando como en una búsqueda binaria donde evaluaremos los extremos, luego el punto intermedio y escogeremos el intervalo que sea más prometedor. Comenzaremos con un intervalo de [1, 594] (594 por que es el total de las muestras) para ver que tal funciona y si se produce un overfitting en el caso de que use tantos estimadores como muestras. A partir de aqui iremos escogiendo el modelo con menores estimadores (menos complejo) que sea capaz de reproducir las mejores prestaciones que otro que si tenga más estimadores."],"metadata":{"id":"yqKm5sHiq9aE"}},{"cell_type":"markdown","source":["Tambien cabe destacar que todos los modelos de random forest los ejecutaremos con el parámetro max_depth = 10 debido a que si no se especifica un límite máximo de profundidad, los árboles de decisión individuales pueden crecer hasta alcanzar la máxima profundidad posible. Esto significa que cada árbol intentará aprender los patrones más específicos y detallados presentes en los datos de entrenamiento.\n","\n","No establecer un límite máximo de profundidad puede resultar en árboles de decisión altamente complejos y profundos, lo que puede llevar a un sobreajuste del modelo."],"metadata":{"id":"xzksWXSoDczE"}},{"cell_type":"code","source":["####################### FUNCION LOOK_FOR_STIMATORS ##########################\n","# Hace una búsqueda recursiva del mejor numero de estimadores para el random forest\n","# Esto lo hacemos evaluando un modelo de Random Forest basico (con todos los parametros por defecto)\n","# excepto el de estimadores que es el que estamos buscando\n","# Basicamente el funcionamiento que hace es evaluar mediante validacion cruzada un modelo con el upper_bound que\n","# hemos indicado, otro con el bottom_bound y uno con la mitad de estos.\n","# Una vez evaluados como la metrica que más nos importa es el RECALL lo que hacemos es comparar si el middle_bound tiene\n","# el mismo valor de RECALL que el upper_bound porque si es asi nos quedariamos con el modelo más simple (el middle_bound ya\n","# que esta capturando la misma información que el que tiene más estimadores por lo cual no es necesario tener más estimadores\n","# porque podriamos entrar en overfitting)\n","# La siguiente comparacion que tenemos es que si el modelo con stimadores = middle_bound tiene el mismo recall o más que\n","# el que tiene bottom_bound y es menor que el de upper_bound buscaremos en el intervalo superior [middle_bound, upper_bound]\n","# y si ninguna de las condiciones anteriores no suceden será porque middle_bound esta funcionando mejor que upper_bound por lo\n","# que terminaremos buscando en el intevalo inferior [bottom_bound, middle_bound]\n","# De esta recursiva conseguiremos quedarnos con el mejor numero de estimadores\n","\n","def look_for_stimators(bottom_bound, upper_bound):\n","\n","  middle_bound = int(round((upper_bound + bottom_bound) / 2))\n","\n","  if (upper_bound - bottom_bound) < 2:\n","    return upper_bound\n","  else:\n","    models = []\n","    models.append([\"RF\" + str(bottom_bound), RandomForestClassifier(n_estimators = bottom_bound, random_state = 42,  max_depth = 10)])\n","    models.append([\"RF\" + str(middle_bound), RandomForestClassifier(n_estimators = middle_bound, random_state = 42, max_depth = 10)])\n","    models.append([\"RF\" + str(upper_bound), RandomForestClassifier(n_estimators = upper_bound, random_state = 42, max_depth = 10)])\n","    df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)\n","\n","    print(\"Recall para \", \"RF\" + str(bottom_bound),  df_to_plot_te[\"RF\" + str(bottom_bound)].loc['RECALL'])\n","    print(\"Recall para \", \"RF\" + str(middle_bound),  df_to_plot_te[\"RF\" + str(middle_bound)].loc['RECALL'])\n","    print(\"Recall para \", \"RF\" + str(upper_bound),  df_to_plot_te[\"RF\" + str(upper_bound)].loc['RECALL'])\n","    print()\n","\n","    if df_to_plot_te[\"RF\" + str(middle_bound)].loc['RECALL'] == df_to_plot_te[\"RF\" + str(upper_bound)].loc['RECALL']:\n","      return look_for_stimators(bottom_bound, middle_bound)\n","    elif df_to_plot_te[\"RF\" + str(middle_bound)].loc['RECALL'] >= df_to_plot_te[\"RF\" + str(bottom_bound)].loc['RECALL'] and df_to_plot_te[\"RF\" + str(middle_bound)].loc['RECALL'] < df_to_plot_te[\"RF\" + str(upper_bound)].loc['RECALL']:\n","      return look_for_stimators(middle_bound, upper_bound)\n","    elif df_to_plot_te[\"RF\" + str(middle_bound)].loc['RECALL'] < df_to_plot_te[\"RF\" + str(bottom_bound)].loc['RECALL'] and df_to_plot_te[\"RF\" + str(middle_bound)].loc['RECALL'] < df_to_plot_te[\"RF\" + str(upper_bound)].loc['RECALL']:\n","      return look_for_stimators(middle_bound, upper_bound)\n","    else:\n","      return look_for_stimators(bottom_bound, middle_bound)\n","\n","\n","upper_bound = 594\n","bottom_bound = 1\n","medida_optima = look_for_stimators(bottom_bound, upper_bound)\n"],"metadata":{"id":"zIIGBOb_Dizu","executionInfo":{"status":"aborted","timestamp":1689078763203,"user_tz":-120,"elapsed":24,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Una vez ya tenemos la medida óptima calculada por la función anterior vamos a entrenar un modelo con cada una de las medidas iniciales (bottom_bound = 1, upper_bound = 594) y la medida optima calculada para ver las metricas de cada uno de ellos y el comportamiento que tienen. La medida optima calculada es la siguiente:"],"metadata":{"id":"_q6Tb-YEEdzh"}},{"cell_type":"code","source":["medida_optima_n_stimators = medida_optima\n","print(\"Valor medida optima: \", medida_optima)"],"metadata":{"id":"TMSdqScPFWnI","executionInfo":{"status":"aborted","timestamp":1689078763204,"user_tz":-120,"elapsed":25,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = []\n","models.append([\"RF\" + str(bottom_bound), RandomForestClassifier(n_estimators = bottom_bound, random_state = 42,  max_depth = 10)])\n","models.append([\"RF\" + str(medida_optima), RandomForestClassifier(n_estimators = medida_optima, random_state = 42, max_depth = 10)])\n","models.append([\"RF\" + str(upper_bound), RandomForestClassifier(n_estimators = upper_bound, random_state = 42, max_depth = 10)])\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"P5I_UdZv06Zx","executionInfo":{"status":"aborted","timestamp":1689078763205,"user_tz":-120,"elapsed":26,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE ENTRENAMIENTO EN CV *********\")\n","df_to_plot_tr"],"metadata":{"id":"sejTFZAX1fzF","executionInfo":{"status":"aborted","timestamp":1689078763205,"user_tz":-120,"elapsed":26,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"flJHk2WOleK2","executionInfo":{"status":"aborted","timestamp":1689078763205,"user_tz":-120,"elapsed":25,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En primer lugar vamos a explicar la grafica que vamos a ver a continuación ya que a partir de aqui la usaremos en los siguientes modelos también.\n","\n","Esta gráfica hace un gráfico de barras por cada una de las metricas, que vemos agrupadas en distintos grupos. Por cada una de las métricas, cada una de las barras es el valor obtenido por el modelo en esa metrica. Cada barra hace referencia a un modelo, por lo que si nos fijamos en una agrupación de barras estaremos viendo el desempeño de los distintos modelos en esa métrica cuyo nombre estará puesto debajo de la agrupación de barras. También según en el titulo del gráfico especificaremos las metricas obtenidas para train o para test (test nos referimos al test dentro de la cross validation)."],"metadata":{"id":"8GcRnup-GIt_"}},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"AwEhF-uxFni-","executionInfo":{"status":"aborted","timestamp":1689078763205,"user_tz":-120,"elapsed":25,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Ahora la conclusión que obtenemos tras ver el resultado obtenido por los modelos es que es el número de estimadores calculado es bastante bueno, debido a que en todas las métricas es mejor que el modelo que solo usa un estimador y es identicamente igual al que usa el numero maximo de estimadores puesto en el intervalo.\n","\n","En Random Forest, aumentar el número de estimadores puede aumentar la capacidad del modelo para capturar patrones complejos y reducir el sesgo. Sin embargo, esto también conlleva un costo computacional mayor, ya que se necesitará más tiempo para entrenar y predecir con un mayor número de estimadores.\n","\n","Si el modelo de Random Forest ya alcanza un nivel óptimo de desempeño con la medida calculada como estimadores y no hay una mejora adicional al aumentar a al número máximo de estimadores, es claro que la medida calculada de estimadores ya esté capturando de manera adecuada la variabilidad y complejidad del conjunto de datos.\n","\n","En este caso, puede ser más eficiente y práctico mantener el número de estimadores en un nivel más bajo (como es la medida calculada) para ahorrar tiempo computacional sin comprometer significativamente la calidad de las predicciones. Además, una menor complejidad del modelo puede reducir el riesgo de sobreajuste a los datos de entrenamiento.\n","\n","Si nos fijamos en el ACCURACY vemos que el modelo que solo tiene un estimador si que se diferencia del resto aunque sigue siendo bastante bueno pero los otros dos modelos si que lo superan significativamente y entre los modelos de la medida calculada y el máximo no hay una diferencia (incluso si miramos la tabla anterior a la grafica sobre la que se genera esta, podemos ver que los valores para todas las metricas son iguales).\n","\n","En cuanto F1-Score vemos que pasa lo mismo que con accuracy el modelo con un estimador se aleja del resto mientras que los otros se mantienen similares lo que nos muestra que la precisión global de los modelos en la clasificación de clases positivas, considerando tanto los falsos positivos como los falsos negativos por lo cual  el modelo tiene una alta capacidad para identificar correctamente tanto los casos positivos como los negativos.\n","\n","En cuanto a AUC-ROC podemos ver que casi lo mismo que en cuanto a F1-Score pero no debemos confudir lo que mide cada una de estas metricas ya que auc-roc se centra en la capacidad del modelo para discriminar entre las clases positiva y negativa en diferentes umbrales de decisión mientras que F1-Score mide la capacidad del modelo para clasificar correctamente los casos positivos.\n","\n","Finalmente llegamos a la métrica que hemos considerado como más importante y en la que al igual que en la métrica anterior pasa lo mismo. Esto nos sugiere que agregar más estimadores no está mejorando significativamente el desempeño del modelo como ya hemos mencionado anteriormente.\n","\n","<br/>\n","\n","Ahora ya que tenemos esto lo que vamos a hacer es añadirle el parametro de class_weight ya que hay un leve desbalance en la clase objetivo con el objetivo de darle un valor mayor a la clase minoritaria."],"metadata":{"id":"DcAFmx1TmlHm"}},{"cell_type":"code","source":["models = []\n","models.append([\"RF No BALANCED\", RandomForestClassifier(n_estimators = medida_optima, random_state = 42 , max_depth = 10)])\n","models.append([\"RF Si BALANCED\", RandomForestClassifier(n_estimators = medida_optima, class_weight = 'balanced', random_state = 42, max_depth = 10)])\n","\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"XkO8uJm9o0vY","executionInfo":{"status":"aborted","timestamp":1689078763206,"user_tz":-120,"elapsed":26,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE ENTRENAMIENTO EN CV *********\")\n","df_to_plot_tr"],"metadata":{"id":"PiJwDuGlpKX0","executionInfo":{"status":"aborted","timestamp":1689078763206,"user_tz":-120,"elapsed":26,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"IUoyQGXcpNgs","executionInfo":{"status":"aborted","timestamp":1689078763206,"user_tz":-120,"elapsed":26,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"bHLsMTpwpEVt","executionInfo":{"status":"aborted","timestamp":1689078763207,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Al estar levemente desbalanceado el uso de este parámetro no nos está aportando los beneficios que si que nos aportaría en un problema que si que está desbalanceado en un mayor grado ya que aquí el peso de las clases no se diferencia tanto y por lo tanto no aporta mucho pero, si que se puede apreciar que mejora levemente el resultado. Si bien esto no es apreciable en la gráfica si que podemos sacar los datos de la tabla que se muestra anteriormente que sobre la que se crea la gráfica anterior."],"metadata":{"id":"wfdwLNnLtluH"}},{"cell_type":"code","source":["df_to_plot_te.loc[\"RECALL\"]"],"metadata":{"id":"oJ8bKF7GJ3Vg","executionInfo":{"status":"aborted","timestamp":1689078763207,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como podemos ver el modelo que hemos creado con el parametro de class_weight con balanceo positivo ha conseguido mejorar aunque levemente el valor del recall consiguiendo así una mejora añadida.\n","\n","Finalmente este es el modelo que propondemos para comparar con el mejor que obtengamos de SVM y RL para elegir cuál modelo es mejor y sobre ese estimaremos el Eout final."],"metadata":{"id":"t7UNUOHzJ27M"}},{"cell_type":"markdown","source":["# **BUSQUEDA Y OPTIMIZACIÓN DE PARÁMETROS PARA EL MODELO SVM**\n"],"metadata":{"id":"Kjsrxhn0pKGO"}},{"cell_type":"markdown","source":["A continuación, explicaremos las distintas configuraciones de los parametros elegidas para SVM:\n","\n","> **C** (float, default = 1.0): Es el parámetro de regularización. Controla la fuerza de la regularización, donde valores más altos de C implican una regularización más débil. C debe ser un número estrictamente positivo.\n","\n","> **kernel** (default = 'rbf'): Especifica el tipo de kernel a utilizar en el algoritmo. Puede ser 'linear' (lineal), 'poly' (polinomial), 'rbf' (función de base radial), 'sigmoid' (sigmoidal) o 'precomputed' (precalculado).\n","\n","> **degree** (int, default = 3): Es el grado de la función de kernel polinomial cuando se utiliza el kernel 'poly'. Debe ser un número entero no negativo. Este parámetro se ignora para otros tipos de kernel.\n","\n","> **gamma** ({'scale', 'auto'} or float, default='scale'): Es el coeficiente del kernel para los kernels 'rbf', 'poly' y 'sigmoid'. 'scale' utiliza el valor 1 / (n_características * X.var()) como gamma, mientras que 'auto' utiliza 1 / n_características.\n","\n","> **coef0** (float, default = 0.0): Es el término independiente en la función de kernel. Solo es relevante cuando se utilizan los kernels 'poly' y 'sigmoid'.\n","\n","> **shrinking** (bool, default = True): Es un booleano que indica si se debe utilizar la heurística de reducción. La reducción puede acelerar el tiempo de entrenamiento para conjuntos de datos grandes.\n","\n","> **probability** (bool, default = False): Es un booleano que indica si se deben habilitar las estimaciones de probabilidad. Si se habilita, el método fit utiliza validación cruzada de 5 pliegues, lo que ralentiza el entrenamiento. Esto es útil si necesitas estimaciones de probabilidad en lugar de solo las etiquetas de clase predichas.\n","\n","> **tol** (float, default = 1e-3): Es la tolerancia para el criterio de parada. Controla la precisión del modelo. Cuanto más bajo sea el valor, más precisa será la solución.\n","\n","> **cache_size** (float, default = 200): Especifica el tamaño de la memoria caché del kernel en megabytes.\n","\n","> **class_weight** (dict or 'balanced', default = None): Si no se proporciona, todas las clases se suponen que tienen peso uno. 'balanced' ajusta automáticamente los pesos de las clases de forma inversamente proporcional a las frecuencias de clase en los datos de entrada n_muestras / (n_clases * np.bincount(y)).\n","\n","> **verbose** (bool, default = False): Es un booleano que indica si se debe habilitar la salida detallada durante el ajuste.\n","\n","> **max_iter** (int, default = -1): Es el límite máximo de iteraciones dentro del solucionador. Puedes establecerlo en -1 para no tener un límite.\n","\n","> **decision_function_shape** ({'ovo','ovr'}, default = 'ovr'): Especifica si se debe devolver una función de decisión uno-contra-todos ('ovr') de forma (n_muestras, n_clases) o la función de decisión original uno-contra-uno ('ovo') de libsvm, que tiene una forma (n_muestras, n_clases * (n_clases - 1) / 2).\n","\n","> **break_ties** (bool, default = False): Es un booleano que indica si, al usar decision_function_shape='ovr' y tener más de 2 clases, se deben romper los empates según los valores de confianza de decision_function. Si es False, se devuelve la primera clase entre las clases empatadas. Tener en cuenta que romper los empates tiene un costo computacional relativamente alto en comparación con una predicción simple. Nuevo en la versión 0.22.\n","\n","> **random_state** (int, RandomState instance or None, default = None): Controla la generación de números pseudoaleatorios para mezclar los datos en el cálculo de estimaciones de probabilidad. Se ignora cuando probability es False. Puedes pasar un número entero para obtener una salida reproducible en llamadas de función múltiples."],"metadata":{"id":"Fef-k-zgWVAy"}},{"cell_type":"markdown","source":["Debido a que el **kernel** se puede considerar como el corazón del algoritmo será el parámetro que escogeremos primero y sobre el cual trabajaremos nuestro modelo. El resto de parámetros a modificar son las variables libres más importantes que son **GAMMA** y **C**. Un parámetro que debemos ajustar para evitar que tarde mucho la ejecución del SVM es el número máximo de iteraciones. Este lo limitaremos a 5000 en todos los modelos para dar rapidez a las ejecuciones.\n","\n","El kernel es responsable de transformar los datos de entrada en un espacio de mayor dimensión donde es más fácil encontrar un hiperplano separador óptimo.\n","\n","En el SVM, el kernel se utiliza para calcular los productos escalares entre pares de muestras en el espacio de características transformado. Esto es esencial para encontrar el hiperplano óptimo que maximiza el margen de separación entre las clases.\n","\n","El kernel permite al SVM trabajar de manera eficiente en problemas donde los datos no son linealmente separables en su espacio de entrada original. Proporciona una forma de mapear los datos a un espacio de mayor dimensión donde la separación lineal es posible.\n","\n","En la práctica viene especificado la recomendación del uso del kernel RBF y POLYNOMIAL pero aún asi vamos a ejecutar un modelo con cada uno de ellos para ver que desempeño tienen sobre nuestro problema (no usaremos lineal ya que hemos escogido SVM como un modelo no lineal para la práctica)."],"metadata":{"id":"SBD8du2GKiZm"}},{"cell_type":"code","source":["models = []\n","models.append(['SVM rbf', SVC(kernel = 'rbf', random_state=42, max_iter = 5000)])\n","models.append(['SVM lineal ', SVC(kernel = 'linear',  random_state=42, max_iter = 5000)])\n","models.append(['SVM poly ', SVC(kernel = 'poly',  random_state=42, max_iter = 5000)])\n","models.append(['SVM sigmoid ', SVC(kernel = 'sigmoid',  random_state=42, max_iter = 5000)])\n","\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"nF2bw8f7pKOa","executionInfo":{"status":"aborted","timestamp":1689078763207,"user_tz":-120,"elapsed":26,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE ENTRENAMIENTO EN CV *********\")\n","df_to_plot_tr"],"metadata":{"id":"XOTBh3WD_WZm","executionInfo":{"status":"aborted","timestamp":1689078763207,"user_tz":-120,"elapsed":26,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"PW1GHH8B_Xi5","executionInfo":{"status":"aborted","timestamp":1689078763208,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"QqhksOZ4HtcG","executionInfo":{"status":"aborted","timestamp":1689078763208,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En terminos generales, todos los modelos de SVM tienen un desempeño bastante bueno de ACCURACY, F1-SCORE, AUC-ROC. Sin embargo, al considerar que estamos tratando un problema de detección de cáncer de pecho, es especiamente importante maximizar el recall para asegurarnos de identificar correctamente los casos positivos de cancer de pecho.\n","\n","Como hemos mencionado anteriormente, en esta practica se recomendaba el uso de un kernel RBF o POLYNOMIAL y efectivamente son los que destacan por encima del resto en la métrica que hemos considerado más importante que es el RECALL.\n","\n","Dado que ambos en la gráfica tiene valores similares vamos a mostrar los datos de la tabla para finalizar nuestra elección sobre el kernel a usar.\n"],"metadata":{"id":"XmmMl7ys0ceI"}},{"cell_type":"code","source":["df_to_plot_te[[df_to_plot_te.columns[0], df_to_plot_te.columns[2]]]"],"metadata":{"id":"7-mOBxjfLyrY","executionInfo":{"status":"aborted","timestamp":1689078763208,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aquí podemos ver de una forma más exacta el valor en métricas de cada uno de los modelos y ya que vemos que tienen un RECALL exactamente igual podemos dejar nuestra elección en el resto de métricas donde claramente se ve superado el modelo con kernel POLYNOMIAL por el modelo que usa kernel RBF aunque por unas pequeñas diferencias.\n","\n","La conclusión a la que llegamos es que el kernel que mejor se ajusta a nuestro problema es el RBF y será con el que mejoraremos nuestro modelo."],"metadata":{"id":"_yuHDtZ9MIzM"}},{"cell_type":"markdown","source":["Ahora ya tenemos un kernel pero como hemos comentado en el modelo anterior (RF) tenemos un leve desbalanceo sobre el conjunto de datos por lo que vamos a añadirle el parametro de class_weight como hicimos con el otro modelo para penalizar los fallos en la clase minoritaria."],"metadata":{"id":"YZx7jDN_Mmce"}},{"cell_type":"code","source":["models = []\n","models.append(['SVM Si BALANCED', SVC(class_weight='balanced',  random_state=42, max_iter = 5000)])\n","models.append(['SVM No BALANCED', SVC(random_state=42, max_iter = 5000)])\n","\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"13BMYpmjIK3A","executionInfo":{"status":"aborted","timestamp":1689078763208,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"v7vfnVRn2KA1","executionInfo":{"status":"aborted","timestamp":1689078763209,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"awmcEyCmIbcV","executionInfo":{"status":"aborted","timestamp":1689078763209,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ambos resutados en SVM tienen un rendimiento similar en términos de ACCURACY, F1-SCORE, AUC-ROC y RECALL. Sin embargo, hay ligeras diferencias en los valores de estas métricas.\n","\n","El modelo SVM No balanceado muestra un rendimiento ligeramente mejor en todas las métricas en comparación con el modelo SVM Balanceado aunque es imperceptible.\n","\n","Esto puede suceder por varias razones:\n","\n","1. **Sesgo hacia la clase mayoritaria**: Al asignar pesos inversamente proporcionales a las clases, el modelo puede volverse demasiado sesgado hacia la clase minoritaria. Esto puede llevar a un bajo rendimiento en la clasificación de la clase mayoritaria y afectar negativamente la precisión global del modelo.\n","\n","2. **Mayor énfasis en casos atípicos**: Al asignar pesos más altos a la clase minoritaria, el modelo puede centrarse demasiado en los casos atípicos o difíciles de clasificar de esa clase. Esto puede conducir a una menor capacidad de generalización y un aumento en los falsos positivos o falsos negativos para la clase mayoritaria.\n","\n","3. **Sensibilidad al umbral de clasificación**: El ajuste de los pesos de clase puede afectar el umbral de clasificación del modelo. Esto puede hacer que el modelo sea más conservador o más agresivo en la predicción de la clase mayoritaria, lo que puede resultar en un rendimiento subóptimo.\n","\n","Basandonos en estos resultados, el modelo SVM no Balanceado prodría considerearse ligeramente mejor en terminos de renidmiento global en comparacion con sl SVM balanceado. Sin embargo, es importante tener en cuenta la diferencia en las métricas es bastante y no pordria ser significativa en la práctica.\n","\n","Pero al tratarse de un problema de detección de cancer, el RECALL adquiere una importancia aún mayor. Dado que el modelo SVM No balanceado y el modelo SVM Balanceado muestras un recall igualmente alto, la diferencia en las otras métricas no es tan relevante. En este caso, podría ser apropiado optar por el modelo SVM balanceado ya que tiene en nuestro problema existe un leve desbalanceo de datos.\n","\n"],"metadata":{"id":"5kh91liS3HXS"}},{"cell_type":"markdown","source":["El siguiente parametro a tratar será el GAMMA. El GAMMA controla la influencia de cada ejemplo de entrenamiento en la formación del límite de decisión. Un valor bajo de gamma significa que la influencia se extiende más lejos, mientras que un valor alto de gamma significa que la influencia se limita a los ejemplos de entrenamiento más cercanos. Lo interesante de optimizar este valor es porque el valor de gamma tiene un impacto significativo en el rendimiento del modelo SVM. Un valor subóptimo de gamma puede llevar a un rendimiento deficiente en términos de precisión y generalización del modelo. Optimizar el gamma permite encontrar el valor que mejor se ajuste a los datos y mejore el rendimiento global del modelo.\n","\n","También es interesante porque controla la flexibilidad del límite de decisión en SVM con kernel como hemos mencionado anteriormente. Un valor bajo de gamma resulta en un límite de decisión suave y generalizado, mientras que un valor alto de gamma produce un límite de decisión más ajustado y adaptado a los datos de entrenamiento. Optimizar gamma permite ajustar la flexibilidad del modelo según las características específicas del problema.\n","\n","Y por último la elección adecuada de gamma puede ayudar a controlar el equilibrio entre el sesgo y la varianza en el modelo SVM. Un valor bajo de gamma puede reducir la varianza pero aumentar el sesgo, lo que puede ser útil en conjuntos de datos con ruido o sobreajuste. Un valor alto de gamma puede reducir el sesgo pero aumentar la varianza, lo que puede ser beneficioso en conjuntos de datos más complejos. Optimizar gamma permite encontrar el equilibrio óptimo para el problema específico.\n","\n","Los dos tipos de gamma que tenemos para usar son:\n","\n","\n","*   Auto: calcula el valor de gamma como $1/n\\_features$, donde $n\\_features$ representa el número de características en los datos de entrenamiento\n","*   Scale calcula el valor de gamma como $1 / (n\\_features * X.var())$, donde $n\\_features$ representa el número de características en los datos de entrenamiento y X.var() la varianza del conjunto de entrenamiento.\n","\n"],"metadata":{"id":"q2U-RTkjN5jM"}},{"cell_type":"code","source":["models = []\n","models.append(['SVM Auto', SVC(random_state=42, max_iter = 5000, gamma = 'auto', class_weight='balanced')])\n","models.append(['SVM Scale', SVC(random_state=42, max_iter = 5000, gamma = 'scale', class_weight='balanced')])\n","\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"uLCcMis837oS","executionInfo":{"status":"aborted","timestamp":1689078763209,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"d08HNJQc4I7L","executionInfo":{"status":"aborted","timestamp":1689078763209,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"1LjB_BPW4JCd","executionInfo":{"status":"aborted","timestamp":1689078763210,"user_tz":-120,"elapsed":28,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En todas las métricas podemos ver que que tienen un valor muy similar pero en cuanto al RECALL que es la métrica que usamos para decantarnos por uno u otro vemos que el modelo que usa gamma auto si que funciona un poquito mejor que el otro por lo que nos quedaremos con este modelo.\n"],"metadata":{"id":"RFh9kGeURQb7"}},{"cell_type":"code","source":["df_to_plot_te.loc[\"RECALL\"]"],"metadata":{"id":"MnJzcCcZSlH7","executionInfo":{"status":"aborted","timestamp":1689078763210,"user_tz":-120,"elapsed":28,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Cuando se establece el valor de gamma en auto, el algoritmo de SVM calcula automáticamente el valor de gamma en función de las características de los datos de entrenamiento.\n","\n","Se utiliza la siguiente fórmula para calcular el valor de gamma:  1/n_features , donde  n_features  representa el número de características en los datos de entrenamiento\n","\n","Esta fórmula asegura que el valor de gamma se ajuste en función de las características y la dispersión de los datos de entrenamiento. En general, un valor más pequeño de gamma significa una influencia más amplia de las muestras de entrenamiento en la frontera de decisión, lo que puede resultar en fronteras más suaves y menos ajustadas a las muestras individuales. Por otro lado, un valor más grande de gamma significa una influencia más concentrada de las muestras de entrenamiento, lo que puede llevar a fronteras de decisión más ajustadas y complejas.\n","\n","Como vemos que mejora mantendremos el gamma en auto para la búsqueda de los siguientes parámetros."],"metadata":{"id":"blJlq-DzSm5O"}},{"cell_type":"markdown","source":["El siguiente parametro que vamos a proceder a buscar es el parámetro **C** que controla la cantidad de regularización aplicada al modelo SVM. La regularización aplicada por este parámetro es la L2 también conocida como Ridge regularization, es una técnica utilizada en el aprendizaje automático para reducir el sobreajuste en modelos lineales. Se basa en la idea de agregar un término adicional a la función de pérdida del modelo, que penaliza los coeficientes grandes.\n","\n","Cuando se aplica la regularización L2, se suma la norma L2 (norma euclidiana) de los coeficientes al objetivo de minimización de la función de pérdida. Esto tiene el efecto de reducir los valores de los coeficientes, ya que penaliza los coeficientes grandes y favorece los coeficientes más pequeños.\n","\n","La regularización L2 es especialmente útil cuando se tienen muchas variables (alta dimensionalidad) o cuando las variables están altamente correlacionadas entre sí (no es nuestro caso). Ayuda a evitar el sobreajuste al limitar la complejidad del modelo y reducir la sensibilidad a variaciones pequeñas en los datos de entrenamiento.\n","\n","En SVM, la regularización se utiliza para evitar el sobreajuste al ajustar el modelo a los datos de entrenamiento. El objetivo es encontrar un equilibrio entre ajustar los datos de entrenamiento y generalizar bien a nuevos datos.\n","\n","$$\\text{Perdida} = \\text{Funcion de perdida original} + \\frac{\\lambda} C \\sum_{j=1}^P β^2_j$$\n","\n","Cuando se establece un valor alto de C, se aplica una regularización más débil. Esto significa que el modelo SVM buscará clasificar correctamente la mayoría de los puntos de datos de entrenamiento, incluso si eso implica ajustar el modelo a ruido o características irrelevantes. En este caso, el modelo puede tener un mayor riesgo de sobreajuste, lo que puede conducir a un rendimiento deficiente en datos no vistos.\n","\n","Por otro lado, cuando se establece un valor bajo de C, se aplica una regularización más fuerte. El modelo SVM buscará un margen más amplio y se concentrará en clasificar correctamente los puntos de datos más importantes. Esto ayuda a evitar el sobreajuste y promueve la generalización del modelo a nuevos datos.\n","\n","La busqueda la realizaremos de la misma forma que hicimos para el parámetro de n_stimators de RF realizando una búsqueda dicotómica a traves de la siguiente función que es la misma que \"look_for_stimators\" solo que hemos modificado los modelos que se evaluan que ahora son SVM y el parámetro a buscar que ahora es C."],"metadata":{"id":"TmfXne9xRT5N"}},{"cell_type":"code","source":["def look_for_C(bottom_bound, upper_bound):\n","\n","  upper_bound = round(upper_bound, 3)\n","  bottom_bound = round(bottom_bound, 3)\n","  middle_bound = round((upper_bound + bottom_bound) / 2, 3)\n","\n","  if middle_bound == upper_bound or middle_bound == bottom_bound:\n","    return middle_bound\n","\n","  else:\n","    models = []\n","    models.append(['SVM ' + str(bottom_bound), SVC(kernel = 'rbf', random_state=42, max_iter = 5000, gamma = 'auto',  class_weight='balanced', C = bottom_bound)])\n","    models.append(['SVM ' + str(middle_bound), SVC(kernel = 'rbf', random_state=42, max_iter = 5000, gamma = 'auto',  class_weight='balanced', C = middle_bound)])\n","    models.append(['SVM ' + str(upper_bound), SVC(kernel = 'rbf', random_state=42, max_iter = 5000, gamma = 'auto',  class_weight='balanced', C = upper_bound)])\n","    df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)\n","\n","    print(\"Recall para \", 'SVM ' + str(bottom_bound),  df_to_plot_te['SVM ' + str(bottom_bound)].loc['RECALL'])\n","    print(\"Recall para \", 'SVM ' + str(middle_bound),  df_to_plot_te['SVM ' + str(middle_bound)].loc['RECALL'])\n","    print(\"Recall para \", 'SVM ' + str(upper_bound),  df_to_plot_te['SVM ' + str(upper_bound)].loc['RECALL'])\n","    print()\n","\n","    if df_to_plot_te[\"SVM \" + str(middle_bound)].loc['RECALL'] == df_to_plot_te[\"SVM \" + str(upper_bound)].loc['RECALL']:\n","      return look_for_C(bottom_bound, middle_bound)\n","    elif df_to_plot_te[\"SVM \" + str(middle_bound)].loc['RECALL'] >= df_to_plot_te[\"SVM \" + str(bottom_bound)].loc['RECALL'] and df_to_plot_te[\"SVM \" + str(middle_bound)].loc['RECALL'] < df_to_plot_te[\"SVM \" + str(upper_bound)].loc['RECALL']:\n","      return look_for_C(middle_bound, upper_bound)\n","    else:\n","      return look_for_C(bottom_bound, middle_bound)\n","\n","\n","upper_bound = 8\n","bottom_bound = 0.001\n","medida_optima = look_for_C(bottom_bound, upper_bound)\n"],"metadata":{"id":"jpA0IkhJ3dVP","executionInfo":{"status":"aborted","timestamp":1689078763210,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La medida optima la hemos buscado en el intervalo [0.001, 8] ya queremos ver como se adapta nuestro modelo aplicando en mayor o menor medida la regularización y asi optar por un mejor C."],"metadata":{"id":"ds8ofRqa2in5"}},{"cell_type":"code","source":["medida_optima_c_svm = medida_optima\n","print(\"Valor medida optima: \", medida_optima)"],"metadata":{"id":"TQLBMt_E2msD","executionInfo":{"status":"aborted","timestamp":1689078763210,"user_tz":-120,"elapsed":27,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora vamos a realizar una comparación de los mismos modelos pero con distinta **C** para ver las métricas de cada uno de los modelos."],"metadata":{"id":"bStjFEDD2sww"}},{"cell_type":"code","source":["models = []\n","models.append(['SVM ' + str(bottom_bound), SVC(kernel = 'rbf', random_state=42, max_iter = 5000, gamma = 'auto', class_weight = 'balanced', C = bottom_bound)])\n","models.append(['SVM ' + str(medida_optima), SVC(kernel = 'rbf', random_state=42, max_iter = 5000, gamma = 'auto', class_weight = 'balanced', C = medida_optima)])\n","models.append(['SVM ' + str(upper_bound), SVC(kernel = 'rbf', random_state=42, max_iter = 5000, gamma = 'auto', class_weight = 'balanced', C = upper_bound)])\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"ScKAb1jB51dk","executionInfo":{"status":"aborted","timestamp":1689078763211,"user_tz":-120,"elapsed":28,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"x6vzt_6R5-7l","executionInfo":{"status":"aborted","timestamp":1689078763211,"user_tz":-120,"elapsed":28,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"T4XITfFL5_D5","executionInfo":{"status":"aborted","timestamp":1689078763211,"user_tz":-120,"elapsed":28,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como vemos el uso de **C** distinto del por defecto mejora notablemente el RECALL de nuestro modelo aunque lo hace empeorar levemente en el resto de métricas. Aún así estamos consiguiendo lo que queremos que es estar lo más cercanos posibles a un RECALL de 1 notandose levemente la mejora del modelo después del ajuste de los parámetros.\n","\n"],"metadata":{"id":"Qjtuor_m7IRq"}},{"cell_type":"code","source":["df_to_plot_te.loc[\"RECALL\"]"],"metadata":{"id":"EaRz4Zcf_O3_","executionInfo":{"status":"aborted","timestamp":1689078763211,"user_tz":-120,"elapsed":28,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Este modelo será el que utilizaremos en la comparación final con el resto de los otros mejores modelos para decidir sobre el cuál haremos la estimación del Eout."],"metadata":{"id":"ukg23H-w_O9a"}},{"cell_type":"markdown","source":["# **BUSQUEDA Y OPTIMIZACIÓN DE PARÁMETROS PARA EL MODELO DE REGRESION LOGISTICA**\n"],"metadata":{"id":"X9i8hVaJpOA9"}},{"cell_type":"markdown","source":["Ahora comentaremos los parametros usados para la Regresión Logistica\n","\n","> **penalty** ({'l1', 'l2', 'elacticnet', None}, default = 'l2'): Especifica el tipo de penalizacion utilizada en la regularización. Puede ser 'l1' para regularización L1, 'l2' para regularización L2 o 'elasticnet' para una combinación de ambas.\n","\n","> **dual** (bool, default = False): Es un booleano que indica si se debe resolver la formulación dual del problema de optimización. La formulación dual es más eficiente cuando el número de características es mayor que el número de muestras. Sin embargo, esta opción solo está disponible cuando penalty='l2' y solver='liblinear'.\n","\n","> **tol** (float, default = 1e-4): Es la tolerancia para el criterio de parada. Controla la precisión del modelo. Cuanto más bajo sea el valor, más precisa será la solución.\n","\n","> **C** (float, default = 1.0): Es el parámetro de regularización inverso. Controla la fuerza de la regularización, donde valores más bajos de C implican una regularización más fuerte. C debe ser un número positivo. El valor predeterminado es 1.0.\n","\n","> **fit_intercept** (bool, default = True): Es un booleano que indica si se debe calcular o no el término de intercepción (sesgo). Si se establece en False, no se calculará el término de intercepción y los datos se centrarán antes de ajustar el modelo.\n","\n","> **intercept_scaling** (float, default = 1): Es un factor que multiplica el término de intercepción (sesgo). Este parámetro solo tiene efecto cuando fit_intercept es True. Puede ser útil para regularizar el término de intercepción.\n","\n","> **class_weight** (dict or 'balanced', default = None): Si no se proporciona, todas las clases se suponen que tienen peso uno. 'balanced' ajusta automáticamente los pesos de las clases de forma inversamente proporcional a las frecuencias de clase en los datos de entrada n_muestras / (n_clases * np.bincount(y)).\n","\n","> **random_state** (int, RandomState instance or None, default = None): Controla la generación de números pseudoaleatorios para mezclar los datos en el cálculo de estimaciones de probabilidad. Se ignora cuando probability es False. Puedes pasar un número entero para obtener una salida reproducible en llamadas de función múltiples.\n","\n","> **solver** ({'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'}, default = 'lbfgs'): Especifica el algoritmo a utilizar en la optimización del problema. Puede ser 'newton-cg', 'lbfgs', 'liblinear', 'sag' o 'saga'.\n","\n","* newton-cg: Utiliza el método de Newton-Conjugate Gradient para optimizar la función de coste. Este algoritmo requiere que la matriz Hessiana (segunda derivada) de la función de coste sea computada y almacenada en memoria. Es adecuado para problemas con conjuntos de datos pequeños o medianos. Sin embargo, no es compatible con la regularización L1 (penalización de la norma L1).\n","\n","* lbfgs (Limited-memory Broyden-Fletcher-Goldfarb-Shanno): Este algoritmo también utiliza aproximaciones de la matriz Hessiana pero con un enfoque de memoria limitada. Es eficiente para conjuntos de datos grandes y suele ser el valor predeterminado para el parámetro solver. Sin embargo, al igual que newton-cg, no es compatible con la regularización L1.\n","\n","* liblinear: Es una biblioteca lineal para aprendizaje automático que se utiliza para problemas de clasificación binaria y regresión logística. Implementa algoritmos de optimización basados en programación lineal, como el método de descenso de coordenadas. Es eficiente en problemas con conjuntos de datos grandes y admite tanto la regularización L1 como la L2. Sin embargo, para problemas multiclase, utiliza una estrategia uno-contra-resto (one-vs-rest).\n","\n","* sag (Stochastic Average Gradient descent): Este algoritmo utiliza una versión estocástica del método del gradiente para optimizar la función de coste. Es adecuado para problemas con conjuntos de datos grandes y puede converger más rápidamente que los métodos determinísticos como newton-cg y lbfgs. Sin embargo, solo admite regularización L2.\n","\n","* saga (SAGA - Stochastic Average Gradient descent): Es una variante mejorada del algoritmo sag que también admite regularización L1. Es útil cuando se desea utilizar la regularización L1 y se tiene un conjunto de datos grande.\n","\n","\n","> **verbose** (bool, default = False): Es un booleano que indica si se debe habilitar la salida detallada durante el ajuste.\n","\n","> **max_iter** (int, default = -1): Es el límite máximo de iteraciones dentro del solucionador. Puedes establecerlo en -1 para no tener un límite.\n","\n","> **multi_class** ({'auto', 'ovr', 'multinomial'}, default = 'auto'): Especifica el enfoque para problemas de clasificación multiclase. Puede ser 'ovr' (one-vs-rest) o 'multinomial'. Si es 'ovr', se ajusta un clasificador binario para cada clase. Si es 'multinomial', se utiliza una estrategia de clasificación multinomial. El valor predeterminado es 'auto', que selecciona automáticamente el enfoque más adecuado según los datos de entrada.\n","\n","> **warm_start** (bool, default = False): Es un booleano que indica si se deben utilizar los coeficientes anteriores como inicialización para el ajuste de la siguiente llamada a fit. Esto permite el ajuste incremental.\n","\n","> **n_jobs** (int, default = None): Especifica el número de trabajos en paralelo para ejecutar durante el ajuste. Puede ser un número entero para indicar el número exacto de trabajos o -1 para utilizar todos los procesadores disponibles.\n","\n","> **l1_ratio** (float, default = None): Es un valor entre 0 y 1 que indica la proporción de la regularización L1 en la regularización elasticnet. Un valor de 0 significa que solo se utiliza regularización L2, mientras que un valor de 1 significa que solo se utiliza regularización L1.\n","\n","\n","\n"],"metadata":{"id":"VxMhSq6BgQLS"}},{"cell_type":"markdown","source":["Es importante tener en cuenta que la elección de solver también está relacionada con la elección de la penalización (L1 o L2) y los demás parametros del modelo. Por tanto, a continuación experimentaremos con los solver y nos quedaremos con el que que mejores resultados nos dé."],"metadata":{"id":"AHAOQQhwAs5O"}},{"cell_type":"code","source":["models = []\n","\n","models.append(['RL lbfgs', LogisticRegression(max_iter=5000, solver = 'lbfgs', random_state=42)])\n","models.append(['RL liblinear', LogisticRegression(max_iter=5000, solver = 'liblinear', random_state=42)])\n","models.append(['RL newton-cg', LogisticRegression(max_iter=5000, solver = 'newton-cg', random_state=42)])\n","models.append(['RL newton-cholesky', LogisticRegression(max_iter=5000, solver = 'newton-cholesky', random_state=42)])\n","models.append(['RL sag', LogisticRegression(max_iter=5000, solver = 'sag', random_state=42)])\n","models.append(['RL saga', LogisticRegression(max_iter=5000, solver = 'saga', random_state=42)])\n","\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"-Pt6XYzfpSjO","executionInfo":{"status":"aborted","timestamp":1689078763212,"user_tz":-120,"elapsed":29,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"L-0izxcSpmm5","executionInfo":{"status":"aborted","timestamp":1689078763212,"user_tz":-120,"elapsed":29,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te, \"train examples\", df_to_plot_te.shape[1])"],"metadata":{"id":"YoeHYx-GJjOQ","executionInfo":{"status":"aborted","timestamp":1689078763212,"user_tz":-120,"elapsed":29,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Debido a que todos los solvers funcionan muy bien a la hora de clasificar nuestros datos y todos tienen un rendimiento muy similar excepto \"liblinear\" que tiene una diferencia muy pequeña vamos a optar por el uso del solver que viene por defecto \"lbfgs\". En el resto de los solvers tienen exactamente los mismo valores en las métricas\n"],"metadata":{"id":"ZzEJuzv7CqHC"}},{"cell_type":"code","source":["df_to_plot_te.loc[\"RECALL\"]"],"metadata":{"id":"LPqVonoBDLMA","executionInfo":{"status":"aborted","timestamp":1689078763212,"user_tz":-120,"elapsed":29,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El algoritmo LBFGS se utiliza para minimizar la función de costo asociada a la regresión logística.\n","\n","El algoritmo LBFGS es una variante de los métodos de Quasi-Newton que se basan en aproximaciones de la matriz Hessiana. A diferencia de otros métodos de optimización, como el descenso de gradiente, LBFGS aprovecha la información de la curvatura de la función objetivo para encontrar la dirección óptima de búsqueda. Además, utiliza una técnica de memoria limitada para almacenar solo una cantidad finita de información histórica, lo que lo hace eficiente en términos de memoria.\n","\n","En resumen, el solver LBFGS para regresión logística es un algoritmo de optimización que busca encontrar los coeficientes óptimos para la función logística mediante la minimización de la función de costo asociada. Es una opción popular debido a su eficiencia en problemas con un gran número de variables y en nuestro caso es el que mejor funciona por lo que optaremos por seguir usandolo para mejorar el modelo."],"metadata":{"id":"EdL4yrhqDOGd"}},{"cell_type":"markdown","source":["El siguiente parámetro que vamos añadirle es el parametro de class_weight ya que hay un leve desbalance en la clase objetivo con el objetivo de darle un valor mayor a la clase minoritaria y lo probaremos como hicimos con el resto de modelos."],"metadata":{"id":"jklcTbQRDWBG"}},{"cell_type":"code","source":["models = []\n","models.append(['RL Si BALANCED', LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000)])\n","models.append(['RL No BALANCED', LogisticRegression(solver='lbfgs', random_state=42, max_iter=150)])\n","\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"qnx4qfSEs2eT","executionInfo":{"status":"aborted","timestamp":1689078763213,"user_tz":-120,"elapsed":29,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"XIMPfJ8vtI__","executionInfo":{"status":"aborted","timestamp":1689078763213,"user_tz":-120,"elapsed":29,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"ccVb8WGGs586","executionInfo":{"status":"aborted","timestamp":1689078763213,"user_tz":-120,"elapsed":29,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Al estar levemente desbalanceado el uso de este parámetro no nos está aportando los beneficios que si que nos aportaría en un problema que si que está desbalanceado en un mayor grado ya que aquí el peso de las clases no se diferencia tanto y por lo tanto no aporta mucho pero si que se puede apreciar que mejora levemente el resultado como ya dijimos en el RF. Y al igual que en RF si bien esto no es tan apreciable en la gráfica si que podemos sacar los datos de la tabla que se muestra anteriormente que es sobre la que se crea esta gráfica."],"metadata":{"id":"OCxu5cjrEOeW"}},{"cell_type":"code","source":["df_to_plot_te.loc[\"RECALL\"]"],"metadata":{"id":"_IaGi85VEW_1","executionInfo":{"status":"aborted","timestamp":1689078763213,"user_tz":-120,"elapsed":29,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como podemos ver el modelo que hemos creado con el parametro de class_weight con balanceo positivo ha conseguido mejorar aunque levemente el valor del recall consiguiendo así una mejora añadida."],"metadata":{"id":"5fQl7H2iEeNz"}},{"cell_type":"markdown","source":["El siguiente valor a optimizar será **C** que controla la cantidad de regularización aplicada al modelo de regresión logistica. La regularización aplicada por este parámetro es la L2. Es la misma que hemos explicado anteriormente para el modelo SVM."],"metadata":{"id":"e8R1h34FEiNe"}},{"cell_type":"code","source":["def look_for_C(bottom_bound, upper_bound):\n","\n","  upper_bound = round(upper_bound, 2)\n","  bottom_bound = round(bottom_bound, 2)\n","  middle_bound = round((upper_bound + bottom_bound) / 2, 2)\n","\n","  if middle_bound == upper_bound or middle_bound == bottom_bound:\n","    return upper_bound\n","\n","  else:\n","    models = []\n","    models.append(['RL ' + str(bottom_bound), LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = bottom_bound)])\n","    models.append(['RL ' + str(middle_bound), LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = middle_bound)])\n","    models.append(['RL ' + str(upper_bound), LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = upper_bound)])\n","    df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)\n","\n","    print(\"Recall para \", 'RL ' + str(bottom_bound),  df_to_plot_te['RL ' + str(bottom_bound)].loc['RECALL'])\n","    print(\"Recall para \", 'RL ' + str(middle_bound),  df_to_plot_te['RL ' + str(middle_bound)].loc['RECALL'])\n","    print(\"Recall para \", 'RL ' + str(upper_bound),  df_to_plot_te['RL ' + str(upper_bound)].loc['RECALL'])\n","    print()\n","\n","    if df_to_plot_te[\"RL \" + str(middle_bound)].loc['RECALL'] == df_to_plot_te[\"RL \" + str(upper_bound)].loc['RECALL']:\n","      return look_for_C(bottom_bound, middle_bound)\n","    elif df_to_plot_te[\"RL \" + str(middle_bound)].loc['RECALL'] >= df_to_plot_te[\"RL \" + str(bottom_bound)].loc['RECALL'] and df_to_plot_te[\"RL \" + str(middle_bound)].loc['RECALL'] < df_to_plot_te[\"RL \" + str(upper_bound)].loc['RECALL']:\n","      return look_for_C(middle_bound, upper_bound)\n","    else:\n","      return look_for_C(bottom_bound, middle_bound)\n","\n","\n","upper_bound = 10\n","bottom_bound = 0.01\n","medida_optima = look_for_C(bottom_bound, upper_bound)"],"metadata":{"id":"n_v1Csm7EN4E","executionInfo":{"status":"aborted","timestamp":1689078763214,"user_tz":-120,"elapsed":30,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La medida optima la hemos buscado en el intervalo [0.01, 10] ya que en la práctica se nos decia que buscasemos hasta una precisión de 2 cifras (enteras o decimales) dando por hecho que la más chica posible es 0.01 y una medida de 10 es grande para C por lo que la medida optima encontrada por nuestra función es la siguiente:"],"metadata":{"id":"g7_NpFeUGFgv"}},{"cell_type":"code","source":["medida_optima_c_rl = medida_optima\n","print(\"Medida optima encontrada para el parametro C:\", medida_optima)"],"metadata":{"id":"mIDDhH5aGGmU","executionInfo":{"status":"aborted","timestamp":1689078763214,"user_tz":-120,"elapsed":30,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = []\n","models.append(['RL ' + str(bottom_bound), LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = bottom_bound)])\n","models.append(['RL ' + str(medida_optima), LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = medida_optima)])\n","models.append(['RL ' + str(upper_bound), LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = upper_bound)])\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"TTsS_BF5UtVV","executionInfo":{"status":"aborted","timestamp":1689078763214,"user_tz":-120,"elapsed":30,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"zp90qF_rU7XP","executionInfo":{"status":"aborted","timestamp":1689078763214,"user_tz":-120,"elapsed":30,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"YPX_dDWFU741","executionInfo":{"status":"aborted","timestamp":1689078763215,"user_tz":-120,"elapsed":31,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Estos valores anteriores representan el rendimiento de los tres modelos de aprendizaje con Regresión Logistica en la tarea de predicción del cancer de pecho.\n","\n","En general, los tres modelos muestran un buen rendimiento, ocn valores de ACCURACY, F1-SCORE, AUC-ROC Y RECALL  superiores al 94%. El modelo RL 0.17 obtiene los mejores resultaods en todas las métricas, seguido por el modelo de RL 0.01."],"metadata":{"id":"60bjP-plVDyl"}},{"cell_type":"markdown","source":["El siguiente parametro a optimizar es el **fit_intercept**. El término de intercepción es un valor constante que se suma a la combinación lineal de las variables independientes para calcular la probabilidad logística en la regresión logística.\n","\n","Cuando fit_intercept se establece en True (valor predeterminado), se ajusta un término de intercepción en el modelo. Esto significa que se considera un efecto constante o un nivel base cuando todas las variables independientes tienen un valor de cero. El valor del término de intercepción se determina durante el ajuste del modelo.\n","\n","Por otro lado, si fit_intercept se establece en False, no se ajusta un término de intercepción en el modelo. Esto implica que la combinación lineal de las variables independientes es directamente utilizada para calcular la probabilidad logística, sin la adición de un valor constante.\n","\n","La elección de utilizar o no un término de intercepción depende del contexto y los datos específicos del problema. En algunos casos, es posible que el modelo no requiera un término de intercepción, como cuando todas las variables independientes tienen un rango completo de valores y no existe un nivel base específico. Sin embargo, en la mayoría de los casos, es recomendable incluir un término de intercepción para tener en cuenta cualquier efecto constante o nivel base.\n","\n","Por ello vamos a ver como se ajusta nuestro modelo segun usemos este parámetro o no."],"metadata":{"id":"Tg803-4GtzXm"}},{"cell_type":"code","source":["models = []\n","models.append(['RL Si Fit Intercept', LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = medida_optima, fit_intercept = True)])\n","models.append(['RL No Fit Intercept', LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = medida_optima, fit_intercept = False)])\n","\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, False)"],"metadata":{"id":"9FCeJ20NH657","executionInfo":{"status":"aborted","timestamp":1689078763215,"user_tz":-120,"elapsed":31,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"Pkq3tlOhIMK2","executionInfo":{"status":"aborted","timestamp":1689078763215,"user_tz":-120,"elapsed":31,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te , \"test folds in cv\", df_to_plot_te.shape[1])"],"metadata":{"id":"UZfRkgJmIMQx","executionInfo":{"status":"aborted","timestamp":1689078763215,"user_tz":-120,"elapsed":31,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dado que nuestro modelo necesita del uso del parámetro fit_intercept podemos asegurar que esto nos ayudará en:\n","\n","Interpretación adecuada: nos ayuda a interpretar los coeficientes del modelo y entender cómo afectan las variables independientes a la variable dependiente, es importante incluir el término de intercepción. Proporciona un valor base o de referencia para el modelo.\n","\n","Completitud del modelo: En la mayoría de los casos, es importante capturar cualquier efecto constante o nivel base en el modelo. El término de intercepción permite tener en cuenta estas fuentes de variación y asegurarse de que el modelo sea completo.\n","\n","Ajuste de la línea base: Al incluir el término de intercepción, el modelo puede ajustar la línea base de la curva logística, lo que puede mejorar la capacidad de predicción y ajuste del modelo a los datos reales.\n","\n","Dicho esto podemos asgurar que nuestro modelo funciona mejor con el valor de fit_intercept a True por lo que lo dejaremos como viene por defecto."],"metadata":{"id":"L9DnDNt8IU6H"}},{"cell_type":"markdown","source":["Este será el modelo que usaremos para la comparación con el resto de modelos."],"metadata":{"id":"bnWUnkqYJYTE"}},{"cell_type":"markdown","source":["# **ELECCIÓN DEL MEJOR MODELO**\n"],"metadata":{"id":"sTIVy3XhpWLv"}},{"cell_type":"code","source":["models = []\n","models.append(['BEST RL', LogisticRegression(solver='lbfgs', random_state=42, class_weight='balanced', max_iter=5000, C = medida_optima_c_rl, fit_intercept = True)])\n","models.append(['BEST SVM', SVC(kernel = 'rbf', random_state=42, max_iter = 5000, gamma = 'auto', class_weight='balanced', C = medida_optima_c_svm)])\n","models.append([\"BEST RF\", RandomForestClassifier(n_estimators = medida_optima_n_stimators, class_weight = 'balanced', random_state = 42, max_depth = 10)])\n","\n","df_to_plot_tr, df_to_plot_te = cv_to_models(models, X_train, y_train, True)"],"metadata":{"id":"okDJ9l8dK3b-","executionInfo":{"status":"aborted","timestamp":1689078763216,"user_tz":-120,"elapsed":31,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"********* TABLA DE METRICAS DE LOS MODELOS SOBRE EL CONJUNTO DE TEST EN CV *********\")\n","df_to_plot_te"],"metadata":{"id":"06m1qf0UpbUs","executionInfo":{"status":"aborted","timestamp":1689078763216,"user_tz":-120,"elapsed":31,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_performance(df_to_plot_te, \"train examples\", df_to_plot_te.shape[1])"],"metadata":{"id":"pjYrJiHWKd9d","executionInfo":{"status":"aborted","timestamp":1689078763216,"user_tz":-120,"elapsed":31,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como venimos diciendo, en un problema de clasificación como el cáncer, la métrica de error protagonista a la hora de tomar decisiones va a ser siempre RECALL ya que se centra en la capacidad del modelo para detectar correctamente los casos de cáncer, minimizando así los falsos negativos. Aunque la precisión sigue siendo relevante, el RECALL proporciona una visión más completa y precisa de la eficacia del modelo en este contexto crítico para la salud.\n","\n","Por tanto como podemos ver en la gráfica anterior, los resultados indican que el modelo SVM obtuvo el mejor rendimiento en todas las metricas excepto en RECALL que tiene el mismo valor que la RL. Esto significa que el modelos SVM logra capturar una alta proporción en casos positivos de cáncer correctamente, minimizando los falsos negativos.\n","\n","Concluimos que el mejor modelo dicho lo anterior es el SVM ya que es el que mejor actúa en el cómputo general de las métricas y mayor RECALL tiene con la RL (siendo mejor SVM que RL en el resto de métricas).\n","\n"],"metadata":{"id":"oRsJ19YqLm_1"}},{"cell_type":"markdown","source":["# **GRAFICAS DEL MEJOR MODELO**\n"],"metadata":{"id":"CZwrbEvUpcaX"}},{"cell_type":"markdown","source":["En este apartado, veremos los resultados del mejor modelo que hemos podido conseguir en el apartado anterior. Comentaremos sobre los valores de los parámetros utilizados:\n","\n","*   **kernel='rbf'**: Este parametro indeica el kernel usado. En este caso, se usará el kernel de función de base radial (RBF). Hemos usado este kernel debido a la flexibilidad para mapear datos en espacios de alta dimensión.\n","\n","*   **random_state=42**: Este parámetro establece una semilla para la generación de números aleratoris. al fijar una semilla, se asegura que los resultados sean reproducibles, es decir, que el modelo genere los mismos resultadoos cada vez que se ejecute\n","\n","*   **max_iter=5000**: Es el límite máximo de iteraciones dentro del solucionador.\n","\n","*   **gamma='auto'**: Es el coeficiente del kernel para los kernels 'rbf', 'poly' y 'sigmoid'. 'auto' utiliza 1 / n_características.\n","\n","*   **C='media_optima_c_svm'**: Este parámetro de regularizacion, controla el equilibrio entre el ajuste a los datos de entrenamiento y la tolerancia a errores de clasificación. La elección de este valor ótimo dependerá del conjunto de datos y la tarea de clasificación específica.\n","\n","*  **class_weight='balanced'**: Si no se proporciona, todas las clases se suponen que tienen peso uno. 'balanced' ajusta automáticamente los pesos de las clases de forma inversamente proporcional a las frecuencias de clase en los datos de entrada n_muestras / (n_clases * np.bincount(y)).\n","\n","A continuación declararemos este modelo y lo volveremos a entrenar con todos los datos de entrenamiento para mostrar las gráficas."],"metadata":{"id":"uCnuzO7_LrvC"}},{"cell_type":"code","source":["best_model = SVC(kernel = 'rbf', random_state=42, max_iter = 5000, gamma = 'auto', class_weight = 'balanced', C = medida_optima_c_svm)"],"metadata":{"id":"IUEj9AgxMJOP","executionInfo":{"status":"aborted","timestamp":1689078763216,"user_tz":-120,"elapsed":31,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model.fit(X_train, y_train)"],"metadata":{"id":"iPgmSRY4Mlv3","executionInfo":{"status":"aborted","timestamp":1689078763217,"user_tz":-120,"elapsed":32,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","cm = confusion_matrix(y_train, best_model.predict(X_train))\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot()\n","plt.show()\n"],"metadata":{"id":"RMPvV7rvMRjP","executionInfo":{"status":"aborted","timestamp":1689078763217,"user_tz":-120,"elapsed":32,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La matriz de confusión nos proporciona una visión general del rendimiento del modelo de clasifiación, permitiendo evaluar las tasas de acierto y error en la clasificación de clases.\n","\n","\n"],"metadata":{"id":"ECsPzZfHqJSA"}},{"cell_type":"markdown","source":["*  **Verdaderos positivos**: casos que realmente son positivos y fueron correctamente clasificados como positivos por el modelo. Estos on los casos que el modelo ha identificado correctamente como cáncer, lo cual  es crucial en la detección temprana y precisa de la enfermedad.\n"],"metadata":{"id":"p5IYC0BTU1Fo"}},{"cell_type":"code","source":["print(\"TN -->\", cm[0][0])"],"metadata":{"id":"bQxodWzFU1eL","executionInfo":{"status":"aborted","timestamp":1689078763217,"user_tz":-120,"elapsed":32,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*   **Falsos positivos**: casos que es negativo, pero fue clasificado como positivo por el modelo. Es decir, estas personan no tenian cancer, pero nuestro modelo indica que si."],"metadata":{"id":"z7e13E9EVFkW"}},{"cell_type":"code","source":["print(\"FP -->\", cm[0][1])"],"metadata":{"id":"OZEOr50QVGDr","executionInfo":{"status":"aborted","timestamp":1689078763217,"user_tz":-120,"elapsed":32,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*   **Falsos negativos**: casso que es positivo en cancer pero han sido clasificados incorrectamente como negativos por el modelo, ya que indica que el modelo no logró detectarlos como cancer. Es importante minimizar estos casos en la detección de cáncer para evitar retrasos en el diagnostico y el tratamiento."],"metadata":{"id":"sAe8CLAyVNjR"}},{"cell_type":"code","source":["print(\"FN -->\", cm[1][0])"],"metadata":{"id":"17rYBd1tVNqo","executionInfo":{"status":"aborted","timestamp":1689078763218,"user_tz":-120,"elapsed":33,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*   **Verdaderos negativos**: Hay 369 que realmente sn negativos y fueron correctamente clasificados como negativos por el modelo. Estos son los casos que el modelo ha identificado correctamente como no cáncer, lo cual es importante para evitar alarmas inecesarias y pruebas adicionales en pacientes sanos.\n"],"metadata":{"id":"4AmFIHWkVNw1"}},{"cell_type":"code","source":["print(\"TP -->\", cm[1][1])"],"metadata":{"id":"VNQE1PG_VN3r","executionInfo":{"status":"aborted","timestamp":1689078763218,"user_tz":-120,"elapsed":33,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","\n","En general este modelo hace una buena aproximación de los datos de train, lo cual indica que es un buen modelo para la práctica."],"metadata":{"id":"TKBeOnGrVe2J"}},{"cell_type":"code","source":["from sklearn.model_selection import learning_curve\n","\n","train_sizes, train_scores, test_scores = learning_curve(best_model,\n","                                                        X_train, y_train, cv=12, scoring = 'recall', random_state=42)\n","plt.title(\"Curvas de aprendizaje sobre el modelo elegido\")\n","plt.plot(train_sizes,1- np.mean(test_scores,axis=1), label = \"Validation Score\")\n","plt.plot(train_sizes,1- np.mean(train_scores,axis=1), label = \"Training Score\")\n","plt.ylabel(\"Expected error\")\n","plt.xlabel(\"Train size\")\n","plt.legend()"],"metadata":{"id":"YtP_ShlM0rOr","executionInfo":{"status":"aborted","timestamp":1689078763218,"user_tz":-120,"elapsed":33,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como podemos ver en la curva de aprendizaje, donde mostramos la relacion nº de datos y RECALL. Podemos ver a medida que elevamos el conjunto de datos el error esperado decrece. Esto significa que a medida que disponemos de más datos para entrenar el modelo, este tiene la capacidad de aprender patrones más precisos y representativos de los datos de entrada.\n","\n","Para un conjunto de datos pequeño, es posible que el modelo no tenga la sufiente información para capturar la complejidad del problema y puede presentar un mayor error. Sin embargo, a medida que agregamos más datos, el modelo tiene una mejor oportunidad de ajustarse a los datos de entrenamiento y generalizar mejor en nuevos ejemplos.\n","\n","En el caso especifico de recall, que se enfoca en la capacidad del modelo para identificar correctamente los casos positivos, una mayor cantidad de datos de entrenamiento proporciona una base más sólida para aprender y mejorar la detección de los casos positivols reales.\n","\n","Es importante tener en cuenta que la curva de aprendizaje puede estabilizarse en un punto donde agragar más datos no tenga un impacto significativo en la mejor de RECALL."],"metadata":{"id":"gaB60oC2utsm"}},{"cell_type":"markdown","source":["Lo siguiente que vamos a ver sobre nuestro mejor modelo es la curva ROC-AUC por lo que vamos a explicar que es y por qué queremos visualizarla:\n","\n","Una buena curva ROC-AUC (Receiver Operating Characteristic - Area Under the Curve) es aquella que se acerca al valor máximo de 1.0 en el área bajo la curva (AUC). La curva ROC-AUC es una representación gráfica del rendimiento de un modelo de clasificación y muestra la relación entre la tasa de verdaderos positivos (True Positive Rate, TPR) y la tasa de falsos positivos (False Positive Rate, FPR) a medida que se varía el umbral de clasificación.\n","\n","Una curva ROC-AUC cercana a 1.0 indica un alto rendimiento del modelo, lo que significa que el modelo tiene una alta capacidad para distinguir correctamente entre las clases positiva y negativa. Esto se traduce en una alta tasa de verdaderos positivos (sensibilidad) y una baja tasa de falsos positivos.\n","\n","En otras palabras, una buena curva ROC-AUC indica que el modelo tiene un buen equilibrio entre la tasa de verdaderos positivos y la tasa de falsos positivos, lo que significa que puede clasificar correctamente la mayoría de las muestras positivas mientras mantiene una baja tasa de errores de clasificación.\n","\n","A continuación vamos a ver la curva ROC-AUC que nos da nuestro modelo para ver como de buena es y como de bueno es enla predicción de verdaderos positivos y verdaderos negativos."],"metadata":{"id":"azNiNvG94aG4"}},{"cell_type":"code","source":["from sklearn.metrics import RocCurveDisplay\n","from sklearn import metrics\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import RocCurveDisplay\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import PrecisionRecallDisplay\n","\n","RocCurveDisplay.from_estimator(best_model, X_train, y_train)\n","plt.title(\"ROC-AUC CURVE FROM BEST MODEL\")\n","plt.show()\n"],"metadata":{"id":"GKivE_mq9-1Q","executionInfo":{"status":"aborted","timestamp":1689078763219,"user_tz":-120,"elapsed":34,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Como podemos ver en la legenda tenemos un muy buen resultado que indica que el modelo tiene una alta capacidad para distinguir entre las clases y tiene un buen equilibrio entre la tasa de verdaderos positivos (sensibilidad) y la tasa de falsos positivos. Esto sugiere que el modelo es efectivo en la tarea de clasificación y tiene un alto nivel de precisión.\n","\n","En general, un AUC como el conseguido se considera un resultado muy bueno y sugiere que el modelo es altamente discriminativo y confiable en la tarea de clasificación. Sin embargo, es importante tener en cuenta que la interpretación del AUC también debe considerar el contexto específico del problema y las características de los datos."],"metadata":{"id":"oI5d_iLU4o3l"}},{"cell_type":"markdown","source":["La curva de precisión-recall muestra la relación entre la precisión y el recall en diferentes umbrales de clasificación para un modelo de clasificación.\n","\n","La curva de precisión-recall traza la precisión en el eje vertical y el recall en el eje horizontal. Cada punto en la curva corresponde a un umbral de clasificación diferente. A medida que se varía el umbral de clasificación, tanto la precisión como el recall pueden cambiar.\n","\n","Idealmente, queremos un modelo con alta precisión y alto recall. Sin embargo, a menudo existe un compromiso entre ambos. A medida que aumentamos el umbral de clasificación para obtener una mayor precisión, es posible que se reduzca el recall, lo que significa que el modelo puede perder algunos casos positivos. Por otro lado, si reducimos el umbral para capturar más casos positivos, es posible que la precisión disminuya, lo que resultaría en más falsos positivos.\n","\n","La curva de precisión-recall muestra cómo se comporta el modelo en este compromiso entre precisión y recall. Una buena curva de precisión-recall se acerca a la esquina superior derecha del gráfico, lo que indica una alta precisión y un alto recall simultáneamente. En contraste, una curva que se acerca a la esquina inferior izquierda indica un rendimiento deficiente del modelo, con baja precisión y bajo recall.\n","\n","La interpretación de la curva de precisión-recall también implica evaluar el área bajo la curva (AUC-PR), que representa la integral de la curva. Un valor de AUC-PR más cercano a 1 indica un mejor rendimiento del modelo en términos de precisión y recall.\n","\n","La visualización de la curva de precisión-recall es interesante en situaciones donde existe un desequilibrio en la distribución de clases o cuando es crucial minimizar los falsos positivos o los falsos negativos como es en nuestro caso."],"metadata":{"id":"fd5Jm09E6ZCV"}},{"cell_type":"code","source":["PrecisionRecallDisplay.from_estimator(best_model, X_train, y_train)\n","plt.title(\"PRECISION-RECALL CURVE FROM BEST MODEL\")\n","plt.show()"],"metadata":{"id":"XPWp5RefQmpQ","executionInfo":{"status":"aborted","timestamp":1689078763219,"user_tz":-120,"elapsed":33,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como podemos ver el valor esta muy cercano a 1 lo que indica que el modelo tiene una alta capacidad para clasificar correctamente los casos positivos y capturar la mayoría de ellos, al mismo tiempo que mantiene una alta precisión. Esto sugiere que el modelo es efectivo en la tarea de clasificación y tiene un alto nivel de precisión y recall que es lo que queriamos conseguir maximizando recall por encima de precision.\n","\n","En general, un AUC-PR de tan cercano a 1 se considera un resultado muy bueno y sugiere que el modelo tiene un excelente rendimiento en términos de precisión y recall. Indica que el modelo es altamente discriminativo y puede realizar clasificaciones precisas tanto en la clase positiva como en la clase negativa."],"metadata":{"id":"SYEAWTQV7GKB"}},{"cell_type":"markdown","source":["# **ESTIMACION DE EOUT**\n"],"metadata":{"id":"FQ7H0q3xp51Z"}},{"cell_type":"markdown","source":["Ahora para la estimacion de $E_{out}$ lo vamos a hacer a partir del conjunto de test inicial que separamos del conjunto de datos y a partir del $E_{cv}$ las formulas las pondremos a continuación cuando calculemos con una fórmula u otra. Va a ser la primera vez que tratemos con el conjunto de test separado al principio."],"metadata":{"id":"ACBiauotDh5E"}},{"cell_type":"markdown","source":["# Estimacion $E_{out}$ a partir de $E_{test}$"],"metadata":{"id":"60dX2LEkD6sO"}},{"cell_type":"markdown","source":["$$E_{out} \\leq E_{test} +  \\sqrt{(\\frac{1}{N})\\ln(\\frac{2}{\\delta})}  $$"],"metadata":{"id":"XkXCLW-KAupV"}},{"cell_type":"markdown","source":["La formula anterior esta relacionada con la teoría y se conoce como cota superior del error fuera de la muestra $E_{out}$.\n","\n","Donde:\n","*   *$E_{out}$*: es el error fuera de la muestra, es decir, el error que el modelo comete al predecir nuevas instancias que no se han usado durante el entrenamiento\n","\n","*   *$E_{test}$*:Es el error de la prueba, que es error cometido por el modelo en el conjunto de datos de prueba.\n","*   *N*: es el tamaño del conjunto de datos utilizado para el entrenamiento.\n","*   *$\\delta$* es la dimensión VC del modelo, que es una madida de su capacidad para ajustarse a diferentes conjuntos de datos.\n","\n","La formula establece el error fuera de la muestra es menor igual al error de prueba mas una cota que está relacionada con la complejidad del modelo, representada por el dimentsion VC ($\\delta$). La dimension VC está relaiconadao con la capacidad del modelo para adaptarse a diferentes patrones en los datos.\n","\n","La cota superior es una medida de la complejidad del modelo en relación al tamaño del conjunto de datos utilizando para el entrenamiento.\n","\n","Esta fórmula proporciona una estimación de la relación enter el error fuera de la muestra y el error de prueba, considerando la complejidad del modelo. Cuanto mayor sea la dimension VC del modelo, mayor será la cota superior del error fuera de la muestra, lo que indica que el modelo puede tener dificultadoes para generalizar correctamente en nuevos datos,"],"metadata":{"id":"qu5e65yx2UTs"}},{"cell_type":"markdown","source":["A continuación vemos los resultados que obtenemos en las distintas metricas de error."],"metadata":{"id":"rR0MnlCy5CAS"}},{"cell_type":"code","source":["best_model.fit(X_train, y_train)\n","pred = best_model.predict(X_test)\n","\n","print('ESTIMACIONES DE EOUT A PARTIR DE EL CONJUNTO DE TEST')\n","print(\"\\nEout en ACCURACY a partir de E_test: \", 1 - ACC(y_test, pred))\n","print(\"Eout en F1 a partir de E_test: \", 1 - F1(y_test, pred))\n","print(\"Eout en ROC-AUC a partir de E_test: \", 1 - ROC(y_test, pred))\n","print(\"Eout en RECALL a partir de E_test: \", 1 - RECALL(y_test, pred))"],"metadata":{"id":"XVNJJW02L7RC","executionInfo":{"status":"aborted","timestamp":1689078763219,"user_tz":-120,"elapsed":33,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Los resultados indican que el modelo tiene un rendimiento sólido en el conjunto de datos de test, con altos valores de exactitud, F1-SCORE, ROC SCORE y RECALL. Estas métricas sugieren que el modelo es capaz de clasificar de manera precisa y efectiva los casos en el conjunto de prueba, lo que es muy prometedor para su aplicación en la detección de cáncer."],"metadata":{"id":"_v9a08pt5Jme"}},{"cell_type":"code","source":["cm = confusion_matrix(y_test, pred)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot()\n","plt.show()\n"],"metadata":{"id":"IPqXXJIrPXFj","executionInfo":{"status":"aborted","timestamp":1689078763219,"user_tz":-120,"elapsed":33,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En nuestro caso, el modelo ha mostrado un buen rendimiento al clasificar correctamente la mayoría de los casos positivos y los casos negativos. Sin embargo, se han cometido algunos flasos positivos, lo que indica que el modelo ha identificado incorrectamente algunos casos negativos.\n","\n","Es importante considerar que el contexto que nos encontramos es en la detección de cancer a partir de unas muestas y que lo más importante es no tener falsos negativos."],"metadata":{"id":"ZWneBQIf8ptq"}},{"cell_type":"markdown","source":["Lo siguiente que veremos a continuación es la curva ROC sobre el conjunto de test de nuestro modelo:"],"metadata":{"id":"bVWFfnCf_oPc"}},{"cell_type":"code","source":["RocCurveDisplay.from_estimator(best_model, X_test, y_test)\n","plt.title(\"ROC-AUC CURVE FROM BEST MODEL\")\n","plt.show()\n"],"metadata":{"id":"i7wL6QACPJ7x","executionInfo":{"status":"aborted","timestamp":1689078763220,"user_tz":-120,"elapsed":34,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como podemos ver ahora hemos hecho la curva roc sobre el conjunto de test y vemos que nos arroja muy buenos resultados como la anterior que hicimos sobre el conjunto de entrenamiento. Al igual que antes el resultado de esta es muy bueno lo que sugiere que nuestro modelo es capaz de discriminar muy bien entre los casos verdaderamente positivos y verdaderamente negativos por lo que podemos concluir que hemos realizado un buen ajuste."],"metadata":{"id":"cwL8V4iM_NRs"}},{"cell_type":"markdown","source":["Lo siguiente que veremos a continuación es la curva precision-recall sobre el conjunto de test de nuestro modelo:"],"metadata":{"id":"o_SqDucL_uqT"}},{"cell_type":"code","source":["PrecisionRecallDisplay.from_estimator(best_model, X_test, y_test)\n","plt.title(\"PRECISION-RECALL CURVE FROM BEST MODEL\")\n","plt.show()"],"metadata":{"id":"KdHgK7l-PZbc","executionInfo":{"status":"aborted","timestamp":1689078763220,"user_tz":-120,"elapsed":34,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En cuanto a la curva precision-recall el resultado es muy bueno como el anterior y vemos que hemos conseguido lo que se prometia que era maximizar el recall para evitar la predicción de los falsos negativos. En la gráfica se puede apreciar ese trade-off del que hemos hablado cuando explicabamos la gráfica que exite entre la precision y el recall. Se puede ver que a la hora de maximizar el recall hemos perdido un poco en cuanto a la precision haciendonos así predecir un número pequeño de casos que son verdaderos negativos ponerlos como falsos positivos. Aún así esto es preferible en nuestro problema porque es peor decirle a una persona que tiene cancer que no lo tiene por eso es crucial el maximizar el recall."],"metadata":{"id":"r2qwsl8v_Zr6"}},{"cell_type":"markdown","source":["# Estimacion $E_{out}$ a partir de $E_{cv}$"],"metadata":{"id":"XNVjqy40EHt9"}},{"cell_type":"markdown","source":["$$E_{cv} = \\frac{1}{N} \\sum_{i=1}^{N}E_{val}(g_i)$$\n","\n","$$  E_{out}(g) \\leq E_{cv}(g) $$"],"metadata":{"id":"DP7q2L8ZBWIt"}},{"cell_type":"markdown","source":["Como hemos visot en las curvas de aprendizaje, generalmente se considera que un modelo se vuelve más confiable a medida que dispone de más datos para entrenarlo. Por lo tanto, para demostrar el rendimiento real del modelo en $E_{out}$,  se recomienda entrenarlo con todos los datos disponibles. Al entrenar el modelo con un counto de datos más grandes, se espera obtener una estimación más precisa y confiable del error fuera de la muestra.\n","\n","Al utiliar todos los datos diponibles para el entrenamiento, se maximiza la información utilizada para construir el modelo, lo que puede conducir a una mejor capacidad de generalización y una menor probabilidad de sobreajuste. Esto permite evaluar el modelo en condiciones más realistas y obtener una estimación más precisa de su rendimiento en datos no vistos previamente"],"metadata":{"id":"n_bklhR72LqB"}},{"cell_type":"code","source":["X_all = pd.concat([X_train, X_test])\n","y_all = pd.concat([y_train, y_test])"],"metadata":{"id":"jzNgFcEkEMYj","executionInfo":{"status":"aborted","timestamp":1689078763221,"user_tz":-120,"elapsed":35,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_training, f1_score_trainig, roc_training, recall_training, accuracy_test, f1_score_test, roc_test, recall_test = own_cv(X_all, y_all, [\"Best Model\", best_model], False)"],"metadata":{"id":"VL7VgyH3Qx2d","executionInfo":{"status":"aborted","timestamp":1689078763221,"user_tz":-120,"elapsed":35,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Estimacion de Eout en ACURACY a partir de Ecv:',1-np.array(accuracy_test).mean())\n","print('Estimacion de Eout en F1-SCORE a partir de Ecv:',1-np.array(f1_score_test).mean())\n","print('Estimacion de Eout en ROC-AUC a partir de Ecv:',1-np.array(roc_test).mean())\n","print('Estimacion de Eout en RECALL a partir de Ecv:',1-np.array(recall_test).mean())"],"metadata":{"id":"0vv3vdbMQ2xt","executionInfo":{"status":"aborted","timestamp":1689078763221,"user_tz":-120,"elapsed":35,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Con estos valores, parece que nuestro modelo tiene un rendimiento bastante bueno en la predicción del cancer de pecho. El error de la precisión es baja, lo que indica que clasifica correctamente el 96.7% de las instancias. El error F1-SCORE es también baja, lo que sugiere un equilibrio enter la precisión y el recall. Además, el error AUC-ROC es bajo, lo que indica que el modelo tiene una buena capacidad para distinguir entre las clases positiva y negativa. El error de RECALL también es bajo, lo que sugiere una buena capacidad del modelo para detectar los casos positivos.\n","\n","En general, estos resultados indican que el modelo tiene un rendimiento sólido en la predicción de cáncer de mama según las métricas proporcionadas.\n"],"metadata":{"id":"X1ChhR3U9xJ2"}},{"cell_type":"markdown","source":["Para finalizar decir que el modelo mejora cuantas más muestras tiene para aprender por lo que el mejor modelo posible a partir del conjunto de datos que tenemos sería el que entrenasemos con todas las muestras que sería el siguiente"],"metadata":{"id":"RL22ecA4EPOi"}},{"cell_type":"code","source":["best_model.fit(X_all, y_all)"],"metadata":{"id":"4JUqhKvIEZfI","executionInfo":{"status":"aborted","timestamp":1689078763221,"user_tz":-120,"elapsed":35,"user":{"displayName":"RUBEN MORILLAS LÓPEZ","userId":"00470945299651638175"}}},"execution_count":null,"outputs":[]}]}